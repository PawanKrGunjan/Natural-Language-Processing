{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385f3b35",
   "metadata": {
    "papermill": {
     "duration": 0.005189,
     "end_time": "2022-11-20T04:31:43.169394",
     "exception": false,
     "start_time": "2022-11-20T04:31:43.164205",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd128783",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T04:31:43.177015Z",
     "iopub.status.busy": "2022-11-20T04:31:43.176583Z",
     "iopub.status.idle": "2022-11-20T04:32:25.000224Z",
     "shell.execute_reply": "2022-11-20T04:32:24.999022Z"
    },
    "papermill": {
     "duration": 41.830128,
     "end_time": "2022-11-20T04:32:25.002878",
     "exception": false,
     "start_time": "2022-11-20T04:31:43.172750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ktrain\r\n",
      "  Downloading ktrain-0.31.10.tar.gz (25.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from ktrain) (1.0.2)\r\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from ktrain) (3.5.3)\r\n",
      "Requirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from ktrain) (1.3.5)\r\n",
      "Requirement already satisfied: fastprogress>=0.1.21 in /opt/conda/lib/python3.7/site-packages (from ktrain) (1.0.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from ktrain) (2.28.1)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from ktrain) (1.0.1)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from ktrain) (21.3)\r\n",
      "Collecting langdetect\r\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: jieba in /opt/conda/lib/python3.7/site-packages (from ktrain) (0.42.1)\r\n",
      "Collecting cchardet\r\n",
      "  Downloading cchardet-2.1.7-cp37-cp37m-manylinux2010_x86_64.whl (263 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.7/263.7 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: chardet in /opt/conda/lib/python3.7/site-packages (from ktrain) (5.0.0)\r\n",
      "Collecting syntok>1.3.3\r\n",
      "  Downloading syntok-1.4.4-py3-none-any.whl (24 kB)\r\n",
      "Collecting transformers==4.17.0\r\n",
      "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from ktrain) (0.1.97)\r\n",
      "Collecting keras_bert>=0.86.0\r\n",
      "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting whoosh\r\n",
      "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.17.0->ktrain) (4.64.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.17.0->ktrain) (1.21.6)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.17.0->ktrain) (0.12.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.17.0->ktrain) (6.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.17.0->ktrain) (3.7.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.17.0->ktrain) (4.13.0)\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==4.17.0->ktrain) (0.0.53)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.17.0->ktrain) (0.10.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.17.0->ktrain) (2021.11.10)\r\n",
      "Collecting keras-transformer==0.40.0\r\n",
      "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting keras-pos-embd==0.13.0\r\n",
      "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting keras-multi-head==0.29.0\r\n",
      "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting keras-layer-normalization==0.16.0\r\n",
      "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting keras-position-wise-feed-forward==0.8.0\r\n",
      "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting keras-embed-sim==0.10.0\r\n",
      "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting keras-self-attention==0.51.0\r\n",
      "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (1.4.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (9.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (4.33.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (3.0.9)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.0.1->ktrain) (2022.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from langdetect->ktrain) (1.15.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->ktrain) (3.3)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->ktrain) (1.26.12)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->ktrain) (2022.9.24)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->ktrain) (2.1.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->ktrain) (3.1.0)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->ktrain) (1.7.3)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17.0->ktrain) (4.1.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.17.0->ktrain) (3.8.0)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.17.0->ktrain) (8.0.4)\r\n",
      "Building wheels for collected packages: ktrain, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect\r\n",
      "  Building wheel for ktrain (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for ktrain: filename=ktrain-0.31.10-py3-none-any.whl size=25312982 sha256=2199028482af9e09fab45b07b630cbfe6f3ec9da186b24f0ef227bb2b3d3d1ca\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/9c/1c/1b/6df2db85720b8f5c6ea5e3ae37313cfc656f248abf910b7cfd\r\n",
      "  Building wheel for keras_bert (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33517 sha256=0d52c9dfaf0bf6212bb85ae9b19d6bd3468345581476df32dfdbdc1e919476aa\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/a4/e8/45/842b3a39831261aef9154b907eacbc4ac99499a99ae829b06f\r\n",
      "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12305 sha256=b49a59129f80fbdab9d38db45a08c8c2138c345764d11bcd4e64a3109d5d5057\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/46/68/26/692ed21edd832833c3b0a0e21615bcacd99ca458b3f9ed571f\r\n",
      "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3960 sha256=23f51cdc98598a8ad534d83d73b78d674abe9a3cc2fab88ca40be8089e9630ba\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/81/67/b5/d847588d075895281e1cf5590f819bd4cf076a554872268bd5\r\n",
      "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4668 sha256=22edbb85377a77552077083a459820803fc0c64f231fef318552742e66b3c6d8\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/5d/1c/2e619f594f69fbcf8bc20943b27d414871c409be053994813e\r\n",
      "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14993 sha256=3ba5de01fd1fcef1fe29c2373e1680e7b2031cfc22b9ad044e1d1abec3d02d2e\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/86/aa/3c/9d15d24005179dae08ff291ce99c754b296347817d076fd9fb\r\n",
      "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6962 sha256=36c92fd0f940a3633a96aa63d7b0e709f3260d380567157acc8c99f65c7d13b3\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/8d/c1/a0/dc44fcf68c857b7ff6be9a97e675e5adf51022eff1169b042f\r\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4983 sha256=5bb7c730fcb02de3278764cc923d5df3e01bfb1ef5d35ecc2f0735bf7f238c7f\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/c2/75/6f/d42f6e051506f442daeba53ff1e2d21a5f20ef8c411610f2bb\r\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18912 sha256=61158949626e4a104000faabaa9f745e8987117f4dc549f992889802aedd33f8\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/95/b1/a8/5ee00cc137940b2f6fa198212e8f45d813d0e0d9c3a04035a3\r\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=cb44ce8a19d80a6dabd39c0d78dbc0ed4c5f2035642f26d086745d8c00a3999a\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\r\n",
      "Successfully built ktrain keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect\r\n",
      "Installing collected packages: whoosh, cchardet, syntok, langdetect, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-layer-normalization, keras-embed-sim, keras-multi-head, keras-transformer, transformers, keras_bert, ktrain\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.20.1\r\n",
      "    Uninstalling transformers-4.20.1:\r\n",
      "      Successfully uninstalled transformers-4.20.1\r\n",
      "Successfully installed cchardet-2.1.7 keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 ktrain-0.31.10 langdetect-1.0.9 syntok-1.4.4 transformers-4.17.0 whoosh-2.7.4\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e0dbc8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T04:32:25.025775Z",
     "iopub.status.busy": "2022-11-20T04:32:25.025013Z",
     "iopub.status.idle": "2022-11-20T04:32:30.729902Z",
     "shell.execute_reply": "2022-11-20T04:32:30.728523Z"
    },
    "papermill": {
     "duration": 5.719156,
     "end_time": "2022-11-20T04:32:30.732698",
     "exception": false,
     "start_time": "2022-11-20T04:32:25.013542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e87f2d25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T04:32:30.771022Z",
     "iopub.status.busy": "2022-11-20T04:32:30.769217Z",
     "iopub.status.idle": "2022-11-20T04:34:43.239091Z",
     "shell.execute_reply": "2022-11-20T04:34:43.238030Z"
    },
    "papermill": {
     "duration": 132.50514,
     "end_time": "2022-11-20T04:34:43.251667",
     "exception": false,
     "start_time": "2022-11-20T04:32:30.746527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input\n",
      "/kaggle/input/imdb-review\n",
      "/kaggle/input/imdb-review/aclImdb\n",
      "/kaggle/input/imdb-review/aclImdb/test\n",
      "/kaggle/input/imdb-review/aclImdb/test/pos\n",
      "/kaggle/input/imdb-review/aclImdb/test/neg\n",
      "/kaggle/input/imdb-review/aclImdb/train\n",
      "/kaggle/input/imdb-review/aclImdb/train/pos\n",
      "/kaggle/input/imdb-review/aclImdb/train/neg\n",
      "/kaggle/input/imdb-review/aclImdb/train/unsup\n",
      "CPU times: user 469 ms, sys: 1.17 s, total: 1.64 s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    #for filename in filenames:\n",
    "    #print(os.path.join(dirname, filenames))\n",
    "    print(dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7484a91",
   "metadata": {
    "papermill": {
     "duration": 0.010502,
     "end_time": "2022-11-20T04:34:43.272677",
     "exception": false,
     "start_time": "2022-11-20T04:34:43.262175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing\n",
    "The texts_from_folder function will load the training and validation data from the specified folder and automatically preprocess it according to BERT's requirements. In doing so, the BERT model and vocabulary will be automatically downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f8e0be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T04:34:43.295453Z",
     "iopub.status.busy": "2022-11-20T04:34:43.294592Z",
     "iopub.status.idle": "2022-11-20T04:42:43.595991Z",
     "shell.execute_reply": "2022-11-20T04:42:43.594643Z"
    },
    "papermill": {
     "duration": 480.315061,
     "end_time": "2022-11-20T04:42:43.598260",
     "exception": false,
     "start_time": "2022-11-20T04:34:43.283199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected encoding: utf-8\n",
      "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
      "[██████████████████████████████████████████████████]\n",
      "extracting pretrained BERT model...\n",
      "done.\n",
      "\n",
      "cleanup downloaded zip...\n",
      "done.\n",
      "\n",
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 46s, sys: 5.65 s, total: 2min 51s\n",
      "Wall time: 8min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "IMDB_DATADIR =\"/kaggle/input/imdb-review/aclImdb\"\n",
    "(x_train, y_train), (x_test, y_test), preproc = ktrain.text.texts_from_folder(IMDB_DATADIR, \n",
    "                                                                              maxlen=500, \n",
    "                                                                              preprocess_mode='bert',\n",
    "                                                                              train_test_names=['train', 'test'],\n",
    "                                                                              classes=['pos', 'neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "195d0ffd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T04:42:43.662888Z",
     "iopub.status.busy": "2022-11-20T04:42:43.661877Z",
     "iopub.status.idle": "2022-11-20T04:42:43.668915Z",
     "shell.execute_reply": "2022-11-20T04:42:43.667762Z"
    },
    "papermill": {
     "duration": 0.041813,
     "end_time": "2022-11-20T04:42:43.670997",
     "exception": false,
     "start_time": "2022-11-20T04:42:43.629184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Model\n",
      "Classes >>> ['neg', 'pos']\n",
      "Tokenizer >>> <keras_bert.tokenizer.Tokenizer object at 0x7f59492b4690>\n",
      "Max Length >>> 500\n",
      "Max Features >>> 20000\n"
     ]
    }
   ],
   "source": [
    "print('BERT Model')\n",
    "print('Classes >>>',preproc.get_classes())\n",
    "print('Tokenizer >>>',preproc.get_tokenizer())\n",
    "print('Max Length >>>',preproc.maxlen)\n",
    "print('Max Features >>>',preproc.max_features)\n",
    "#print('Token Dictionary >>>',preproc.tok_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc8eed3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T04:42:43.734637Z",
     "iopub.status.busy": "2022-11-20T04:42:43.733670Z",
     "iopub.status.idle": "2022-11-20T04:42:43.745525Z",
     "shell.execute_reply": "2022-11-20T04:42:43.744145Z"
    },
    "papermill": {
     "duration": 0.045435,
     "end_time": "2022-11-20T04:42:43.747652",
     "exception": false,
     "start_time": "2022-11-20T04:42:43.702217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Training Data : 2\n",
      "\n",
      "Training Label Shape: (25000, 2) \n",
      " [[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "\n",
      "Training Input, Shape : (25000, 500) \n",
      " [[ 101 5717 2154 ...    0    0    0]\n",
      " [ 101 2616 2064 ...    0    0    0]\n",
      " [ 101 3071 3248 ...    0    0    0]\n",
      " ...\n",
      " [ 101 3083 3427 ...    0    0    0]\n",
      " [ 101 1045 3422 ...    0    0    0]\n",
      " [ 101 7078 1996 ...    0    0    0]]\n",
      "\n",
      "Training Mask, Shape : (25000, 500) \n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "********************\n",
      "Testing Data : 2\n",
      "\n",
      "Testing Label Shape: (25000, 2) \n",
      " [[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "\n",
      "Testing Input, Shape : (25000, 500) \n",
      " [[ 101 5717 2154 ...    0    0    0]\n",
      " [ 101 2616 2064 ...    0    0    0]\n",
      " [ 101 3071 3248 ...    0    0    0]\n",
      " ...\n",
      " [ 101 3083 3427 ...    0    0    0]\n",
      " [ 101 1045 3422 ...    0    0    0]\n",
      " [ 101 7078 1996 ...    0    0    0]]\n",
      "\n",
      "Testing Mask, Shape : (25000, 500) \n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print('*'*20)\n",
    "print('Training Data :',len(x_train))\n",
    "print('\\nTraining Label Shape:',y_train.shape,'\\n',y_train)\n",
    "print('\\nTraining Input, Shape :',x_train[0].shape,'\\n',x_train[0])\n",
    "print('\\nTraining Mask, Shape :',x_train[1].shape,'\\n',x_train[1])\n",
    "\n",
    "print('*'*20)\n",
    "print('Testing Data :',len(x_train))\n",
    "print('\\nTesting Label Shape:',y_train.shape,'\\n',y_train)\n",
    "print('\\nTesting Input, Shape :',x_train[0].shape,'\\n',x_train[0])\n",
    "print('\\nTesting Mask, Shape :',x_train[1].shape,'\\n',x_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2d81af",
   "metadata": {
    "papermill": {
     "duration": 0.030456,
     "end_time": "2022-11-20T04:42:43.809117",
     "exception": false,
     "start_time": "2022-11-20T04:42:43.778661",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading a pre trained BERT and wrapping it in a ktrain.learner object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a48ca44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T04:42:43.871617Z",
     "iopub.status.busy": "2022-11-20T04:42:43.870651Z",
     "iopub.status.idle": "2022-11-20T04:42:53.137229Z",
     "shell.execute_reply": "2022-11-20T04:42:53.136221Z"
    },
    "papermill": {
     "duration": 9.30028,
     "end_time": "2022-11-20T04:42:53.139696",
     "exception": false,
     "start_time": "2022-11-20T04:42:43.839416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 500\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "model = ktrain.text.text_classifier('bert', (x_train, y_train), preproc=preproc)\n",
    "learner = ktrain.get_learner(model,train_data=(x_train, y_train), val_data=(x_test, y_test), batch_size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084b1774",
   "metadata": {
    "papermill": {
     "duration": 0.031227,
     "end_time": "2022-11-20T04:42:53.202928",
     "exception": false,
     "start_time": "2022-11-20T04:42:53.171701",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training and Tuning the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e1bfcf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T04:42:53.266848Z",
     "iopub.status.busy": "2022-11-20T04:42:53.265856Z",
     "iopub.status.idle": "2022-11-20T05:27:33.988945Z",
     "shell.execute_reply": "2022-11-20T05:27:33.987989Z"
    },
    "papermill": {
     "duration": 2680.75724,
     "end_time": "2022-11-20T05:27:33.991230",
     "exception": false,
     "start_time": "2022-11-20T04:42:53.233990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 2e-05...\n",
      "4167/4167 [==============================] - 2664s 635ms/step - loss: 0.2494 - accuracy: 0.8986 - val_loss: 0.1703 - val_accuracy: 0.9354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f593d373b50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit_onecycle(lr =2e-5, epochs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac2c64d",
   "metadata": {
    "papermill": {
     "duration": 0.296193,
     "end_time": "2022-11-20T05:27:34.531879",
     "exception": false,
     "start_time": "2022-11-20T05:27:34.235686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Reference\n",
    "[BERT Text Classification in 3 Lines of Code Using Keras](https://towardsdatascience.com/bert-text-classification-in-3-lines-of-code-using-keras-264db7e7a358)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3361.878019,
   "end_time": "2022-11-20T05:27:37.529736",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-20T04:31:35.651717",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
