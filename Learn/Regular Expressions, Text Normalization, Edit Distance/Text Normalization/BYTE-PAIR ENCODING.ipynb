{
 "cells": [
  {
   "cell_type": "raw",
   "id": "8dfba89f",
   "metadata": {},
   "source": [
    "function BYTE-PAIR ENCODING(strings C, number of merges k) returns vocab V\n",
    "V←all unique characters in C # initial set of tokens is characters\n",
    "for i = 1 to k do # merge tokens til k times\n",
    "tL, tR ←Most frequent pair of adjacent tokens in C\n",
    "tNEW ←tL + tR # make new token by concatenating\n",
    "V←V + tNEW # update the vocabulary\n",
    "Replace each occurrence of tL, tR in C with tNEW # and update the corpus\n",
    "return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "350e67e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2415e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['n', 'i', 'o', ' ', 'd', 't', 'l', 'e', 'r', 'w', 's'],\n",
       " [8, 3, 7, 17, 3, 2, 7, 19, 9, 18, 2]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'low low low low low lowest lowest newer newer newer newer newer newer wider wider wider new new'\n",
    "chars = [char for char in string]\n",
    "Unique = list(set(chars))\n",
    "l = [[0 for i in range(len(Unique))] for i in range(2)] \n",
    "l[0] = Unique\n",
    "for i in range(len(Unique)):\n",
    "    l[1][i]= chars.count(Unique[i])\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "143ff3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newer', 'wider', 'low', 'lowest', 'new']\n",
      "Vocabulary size: 5\n"
     ]
    }
   ],
   "source": [
    "## get the word frequency and add the end of word (</w>) token ## at the end of each word\n",
    "\n",
    "patterns = \"([A-Z]+\\.)+|\\$?\\d+(\\.\\d+)?%?|\\w+(-\\w+)?(\\.\\w)?|\\.+?\"\n",
    "Token = []\n",
    "for i in re.finditer(patterns,string):\n",
    "    Token.append(i.group())\n",
    "tokens = list(set(Token))\n",
    "print(tokens)\n",
    "print(f\"Vocabulary size: {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fc436b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'l o w _': 5,\n",
       "             'l o w e s t _': 2,\n",
       "             'n e w e r _': 6,\n",
       "             'w i d e r _': 3,\n",
       "             'n e w _': 2})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq_dict = collections.defaultdict(int)\n",
    "\n",
    "for word in Token:\n",
    "    word_freq_dict[' '.join(word) + ' _'] += 1\n",
    "\n",
    "word_freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0f4fbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'l': 7,\n",
       "             'o': 7,\n",
       "             'w': 18,\n",
       "             '_': 18,\n",
       "             'e': 19,\n",
       "             's': 2,\n",
       "             't': 2,\n",
       "             'n': 8,\n",
       "             'r': 9,\n",
       "             'i': 3,\n",
       "             'd': 3})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_freq_dict = collections.defaultdict(int)\n",
    "for word, freq in word_freq_dict.items():\n",
    "    chars = word.split()\n",
    "    for char in chars:\n",
    "        char_freq_dict[char] += freq\n",
    "\n",
    "char_freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caad5b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {('l', 'o'): 7,\n",
       "             ('o', 'w'): 7,\n",
       "             ('w', '_'): 7,\n",
       "             ('w', 'e'): 8,\n",
       "             ('e', 's'): 2,\n",
       "             ('s', 't'): 2,\n",
       "             ('t', '_'): 2,\n",
       "             ('n', 'e'): 8,\n",
       "             ('e', 'w'): 8,\n",
       "             ('e', 'r'): 9,\n",
       "             ('r', '_'): 9,\n",
       "             ('w', 'i'): 3,\n",
       "             ('i', 'd'): 3,\n",
       "             ('d', 'e'): 3})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "## create all possible consecutive pairs\n",
    "pairs = collections.defaultdict(int)\n",
    "for word, freq in word_freq_dict.items():\n",
    "    chars = word.split()\n",
    "    for i in range(len(chars)-1):\n",
    "        pairs[chars[i], chars[i+1]] += freq\n",
    "\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08630902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('e', 'r')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(pairs, key=pairs.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66517e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "##find the best pair\n",
    "\n",
    "def get_pairs(word_freq_dict):\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for word, freq in word_freq_dict.items():\n",
    "        chars = word.split()\n",
    "        for i in range(len(chars)-1):\n",
    "            pairs[chars[i], chars[i+1]] += freq\n",
    "    return pairs\n",
    "\n",
    "def merge_byte_pairs(best_pair, word_freq_dict):\n",
    "    print(best_pair)\n",
    "    merged_dict = {}\n",
    "    bigram = re.escape(' '.join(best_pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    for word in word_freq_dict:\n",
    "        # print(word)\n",
    "        w_out = p.sub(''.join(best_pair), word)\n",
    "        merged_dict[w_out] = word_freq_dict[word]\n",
    "    return merged_dict\n",
    "\n",
    "def get_subword_tokens(word_freq_dict):\n",
    "    char_freq_dict = collections.defaultdict(int)\n",
    "    for word, freq in word_freq_dict.items():\n",
    "        chars = word.split()\n",
    "        for char in chars:\n",
    "            char_freq_dict[char] += freq\n",
    "    return char_freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00f3f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BYTE_PAIR_ENCODING(iteration, word_freq_dict):\n",
    "    Vocab = list(char_freq_dict.keys())\n",
    "    try:\n",
    "        for i in range(iteration):\n",
    "            pairs = get_pairs(word_freq_dict)\n",
    "            best_pair = max(pairs, key=pairs.get)\n",
    "            print(f\"Iteration {i}: \")\n",
    "            word_freq_dict = merge_byte_pairs(best_pair, word_freq_dict)\n",
    "            # print(word_freq_dict)\n",
    "            subword_tokens = get_subword_tokens(word_freq_dict)\n",
    "            print(subword_tokens)\n",
    "            print(len(subword_tokens))\n",
    "            print(\"--------\")\n",
    "            Vocab.append(''.join(best_pair))\n",
    "    except:\n",
    "        return Vocab\n",
    "\n",
    "    return Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "954639c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: \n",
      "('e', 'r')\n",
      "defaultdict(<class 'int'>, {'l': 7, 'o': 7, 'w': 18, '_': 18, 'e': 10, 's': 2, 't': 2, 'n': 8, 'er': 9, 'i': 3, 'd': 3})\n",
      "11\n",
      "--------\n",
      "Iteration 1: \n",
      "('er', '_')\n",
      "defaultdict(<class 'int'>, {'l': 7, 'o': 7, 'w': 18, '_': 9, 'e': 10, 's': 2, 't': 2, 'n': 8, 'er_': 9, 'i': 3, 'd': 3})\n",
      "11\n",
      "--------\n",
      "Iteration 2: \n",
      "('n', 'e')\n",
      "defaultdict(<class 'int'>, {'l': 7, 'o': 7, 'w': 18, '_': 9, 'e': 2, 's': 2, 't': 2, 'ne': 8, 'er_': 9, 'i': 3, 'd': 3})\n",
      "11\n",
      "--------\n",
      "Iteration 3: \n",
      "('ne', 'w')\n",
      "defaultdict(<class 'int'>, {'l': 7, 'o': 7, 'w': 10, '_': 9, 'e': 2, 's': 2, 't': 2, 'new': 8, 'er_': 9, 'i': 3, 'd': 3})\n",
      "11\n",
      "--------\n",
      "Iteration 4: \n",
      "('l', 'o')\n",
      "defaultdict(<class 'int'>, {'lo': 7, 'w': 10, '_': 9, 'e': 2, 's': 2, 't': 2, 'new': 8, 'er_': 9, 'i': 3, 'd': 3})\n",
      "10\n",
      "--------\n",
      "Iteration 5: \n",
      "('lo', 'w')\n",
      "defaultdict(<class 'int'>, {'low': 7, '_': 9, 'e': 2, 's': 2, 't': 2, 'new': 8, 'er_': 9, 'w': 3, 'i': 3, 'd': 3})\n",
      "10\n",
      "--------\n",
      "Iteration 6: \n",
      "('new', 'er_')\n",
      "defaultdict(<class 'int'>, {'low': 7, '_': 9, 'e': 2, 's': 2, 't': 2, 'newer_': 6, 'w': 3, 'i': 3, 'd': 3, 'er_': 3, 'new': 2})\n",
      "11\n",
      "--------\n",
      "Iteration 7: \n",
      "('low', '_')\n",
      "defaultdict(<class 'int'>, {'low_': 5, 'low': 2, 'e': 2, 's': 2, 't': 2, '_': 4, 'newer_': 6, 'w': 3, 'i': 3, 'd': 3, 'er_': 3, 'new': 2})\n",
      "12\n",
      "--------\n",
      "Iteration 8: \n",
      "('w', 'i')\n",
      "defaultdict(<class 'int'>, {'low_': 5, 'low': 2, 'e': 2, 's': 2, 't': 2, '_': 4, 'newer_': 6, 'wi': 3, 'd': 3, 'er_': 3, 'new': 2})\n",
      "11\n",
      "--------\n",
      "Iteration 9: \n",
      "('wi', 'd')\n",
      "defaultdict(<class 'int'>, {'low_': 5, 'low': 2, 'e': 2, 's': 2, 't': 2, '_': 4, 'newer_': 6, 'wid': 3, 'er_': 3, 'new': 2})\n",
      "10\n",
      "--------\n",
      "Iteration 10: \n",
      "('wid', 'er_')\n",
      "defaultdict(<class 'int'>, {'low_': 5, 'low': 2, 'e': 2, 's': 2, 't': 2, '_': 4, 'newer_': 6, 'wider_': 3, 'new': 2})\n",
      "9\n",
      "--------\n",
      "Iteration 11: \n",
      "('low', 'e')\n",
      "defaultdict(<class 'int'>, {'low_': 5, 'lowe': 2, 's': 2, 't': 2, '_': 4, 'newer_': 6, 'wider_': 3, 'new': 2})\n",
      "8\n",
      "--------\n",
      "Iteration 12: \n",
      "('lowe', 's')\n",
      "defaultdict(<class 'int'>, {'low_': 5, 'lowes': 2, 't': 2, '_': 4, 'newer_': 6, 'wider_': 3, 'new': 2})\n",
      "7\n",
      "--------\n",
      "Iteration 13: \n",
      "('lowes', 't')\n",
      "defaultdict(<class 'int'>, {'low_': 5, 'lowest': 2, '_': 4, 'newer_': 6, 'wider_': 3, 'new': 2})\n",
      "6\n",
      "--------\n",
      "Iteration 14: \n",
      "('lowest', '_')\n",
      "defaultdict(<class 'int'>, {'low_': 5, 'lowest_': 2, 'newer_': 6, 'wider_': 3, 'new': 2, '_': 2})\n",
      "6\n",
      "--------\n",
      "Iteration 15: \n",
      "('new', '_')\n",
      "defaultdict(<class 'int'>, {'low_': 5, 'lowest_': 2, 'newer_': 6, 'wider_': 3, 'new_': 2})\n",
      "5\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "Vocab = BYTE_PAIR_ENCODING(50, word_freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0284f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Vocab : 27\n",
      "Vocab : ['l', 'o', 'w', '_', 'e', 's', 't', 'n', 'r', 'i', 'd', 'er', 'er_', 'ne', 'new', 'lo', 'low', 'newer_', 'low_', 'wi', 'wid', 'wider_', 'lowe', 'lowes', 'lowest', 'lowest_', 'new_']\n"
     ]
    }
   ],
   "source": [
    "print('Length of Vocab :',len(Vocab))\n",
    "print('Vocab :',Vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
