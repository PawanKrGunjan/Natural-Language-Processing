{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/pawankumargunjan/automatic-speech-recognition-using-transformer?scriptVersionId=183678468\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"86caa19f","metadata":{"papermill":{"duration":0.006382,"end_time":"2024-06-15T13:50:41.469693","exception":false,"start_time":"2024-06-15T13:50:41.463311","status":"completed"},"tags":[]},"source":["# Import the necessary Libraries"]},{"cell_type":"code","execution_count":1,"id":"a53b9850","metadata":{"execution":{"iopub.execute_input":"2024-06-15T13:50:41.483834Z","iopub.status.busy":"2024-06-15T13:50:41.483064Z","iopub.status.idle":"2024-06-15T13:50:51.127431Z","shell.execute_reply":"2024-06-15T13:50:51.126441Z"},"papermill":{"duration":9.653813,"end_time":"2024-06-15T13:50:51.129884","exception":false,"start_time":"2024-06-15T13:50:41.476071","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"]}],"source":["import os\n","import random\n","from glob import glob\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers"]},{"cell_type":"markdown","id":"d3c82443","metadata":{"papermill":{"duration":0.006195,"end_time":"2024-06-15T13:50:51.142376","exception":false,"start_time":"2024-06-15T13:50:51.136181","status":"completed"},"tags":[]},"source":["# Define the Transformer Input Layer"]},{"cell_type":"code","execution_count":2,"id":"0e5bc6cd","metadata":{"execution":{"iopub.execute_input":"2024-06-15T13:50:51.155706Z","iopub.status.busy":"2024-06-15T13:50:51.155086Z","iopub.status.idle":"2024-06-15T13:50:51.162455Z","shell.execute_reply":"2024-06-15T13:50:51.16162Z"},"papermill":{"duration":0.015974,"end_time":"2024-06-15T13:50:51.164296","exception":false,"start_time":"2024-06-15T13:50:51.148322","status":"completed"},"tags":[]},"outputs":[],"source":["class TokenEmbedding(layers.Layer):\n","    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n","        super().__init__()\n","        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n","        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n","\n","    def call(self, x):\n","        maxlen = tf.shape(x)[-1]\n","        x = self.emb(x)\n","        positions = tf.range(start=0, limit=maxlen, delta=1)\n","        positions = self.pos_emb(positions)\n","        return x + positions"]},{"cell_type":"code","execution_count":3,"id":"b7d5b945","metadata":{"execution":{"iopub.execute_input":"2024-06-15T13:50:51.177281Z","iopub.status.busy":"2024-06-15T13:50:51.177014Z","iopub.status.idle":"2024-06-15T13:50:51.183523Z","shell.execute_reply":"2024-06-15T13:50:51.182649Z"},"papermill":{"duration":0.01533,"end_time":"2024-06-15T13:50:51.185464","exception":false,"start_time":"2024-06-15T13:50:51.170134","status":"completed"},"tags":[]},"outputs":[],"source":["class SpeechFeatureEmbedding(layers.Layer):\n","    def __init__(self, num_hid=64, maxlen=100):\n","        super().__init__()\n","        self.conv1 = tf.keras.layers.Conv1D(\n","            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n","        )\n","        self.conv2 = tf.keras.layers.Conv1D(\n","            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n","        )\n","        self.conv3 = tf.keras.layers.Conv1D(\n","            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n","        )\n","\n","    def call(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        return self.conv3(x)"]},{"cell_type":"markdown","id":"3482a7c2","metadata":{"papermill":{"duration":0.005663,"end_time":"2024-06-15T13:50:51.197017","exception":false,"start_time":"2024-06-15T13:50:51.191354","status":"completed"},"tags":[]},"source":["# Transformer Encoder Layer"]},{"cell_type":"code","execution_count":4,"id":"c3d0294c","metadata":{"execution":{"iopub.execute_input":"2024-06-15T13:50:51.210118Z","iopub.status.busy":"2024-06-15T13:50:51.209851Z","iopub.status.idle":"2024-06-15T13:50:51.217366Z","shell.execute_reply":"2024-06-15T13:50:51.216539Z"},"papermill":{"duration":0.016179,"end_time":"2024-06-15T13:50:51.21934","exception":false,"start_time":"2024-06-15T13:50:51.203161","status":"completed"},"tags":[]},"outputs":[],"source":["class TransformerEncoder(layers.Layer):\n","    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n","        super().__init__()\n","        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","        self.ffn = keras.Sequential(\n","            [\n","                layers.Dense(feed_forward_dim, activation=\"relu\"),\n","                layers.Dense(embed_dim),\n","            ]\n","        )\n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = layers.Dropout(rate)\n","        self.dropout2 = layers.Dropout(rate)\n","\n","    def call(self, inputs, training):\n","        attn_output = self.att(inputs, inputs)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(inputs + attn_output)\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        return self.layernorm2(out1 + ffn_output)"]},{"cell_type":"markdown","id":"4642ea5e","metadata":{"papermill":{"duration":0.005685,"end_time":"2024-06-15T13:50:51.230876","exception":false,"start_time":"2024-06-15T13:50:51.225191","status":"completed"},"tags":[]},"source":["# Transformer Decoder Layer"]},{"cell_type":"code","execution_count":5,"id":"fc279e1e","metadata":{"execution":{"iopub.execute_input":"2024-06-15T13:50:51.243885Z","iopub.status.busy":"2024-06-15T13:50:51.243622Z","iopub.status.idle":"2024-06-15T13:50:51.256251Z","shell.execute_reply":"2024-06-15T13:50:51.255389Z"},"papermill":{"duration":0.021382,"end_time":"2024-06-15T13:50:51.258107","exception":false,"start_time":"2024-06-15T13:50:51.236725","status":"completed"},"tags":[]},"outputs":[],"source":["class TransformerDecoder(layers.Layer):\n","    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n","        super().__init__()\n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n","        self.self_att = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","        self.self_dropout = layers.Dropout(0.5)\n","        self.enc_dropout = layers.Dropout(0.1)\n","        self.ffn_dropout = layers.Dropout(0.1)\n","        self.ffn = keras.Sequential(\n","            [\n","                layers.Dense(feed_forward_dim, activation=\"relu\"),\n","                layers.Dense(embed_dim),\n","            ]\n","        )\n","\n","    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n","        \"\"\"Masks the upper half of the dot product matrix in self attention.\n","\n","        This prevents flow of information from future tokens to current token.\n","        1's in the lower triangle, counting from the lower right corner.\n","        \"\"\"\n","        i = tf.range(n_dest)[:, None]\n","        j = tf.range(n_src)\n","        m = i >= j - n_src + n_dest\n","        mask = tf.cast(m, dtype)\n","        mask = tf.reshape(mask, [1, n_dest, n_src])\n","        mult = tf.concat(\n","            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n","        )\n","        return tf.tile(mask, mult)\n","\n","    def call(self, enc_out, target):\n","        input_shape = tf.shape(target)\n","        batch_size = input_shape[0]\n","        seq_len = input_shape[1]\n","        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n","        target_att = self.self_att(target, target, attention_mask=causal_mask)\n","        target_norm = self.layernorm1(target + self.self_dropout(target_att))\n","        enc_out = self.enc_att(target_norm, enc_out)\n","        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out) + target_norm)\n","        ffn_out = self.ffn(enc_out_norm)\n","        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out))\n","        return ffn_out_norm"]},{"cell_type":"markdown","id":"57d04412","metadata":{"papermill":{"duration":0.00561,"end_time":"2024-06-15T13:50:51.269759","exception":false,"start_time":"2024-06-15T13:50:51.264149","status":"completed"},"tags":[]},"source":["# Complete the Transformer model"]},{"cell_type":"code","execution_count":6,"id":"b45739a6","metadata":{"execution":{"iopub.execute_input":"2024-06-15T13:50:51.283366Z","iopub.status.busy":"2024-06-15T13:50:51.283104Z","iopub.status.idle":"2024-06-15T13:50:51.301731Z","shell.execute_reply":"2024-06-15T13:50:51.300951Z"},"papermill":{"duration":0.027731,"end_time":"2024-06-15T13:50:51.303573","exception":false,"start_time":"2024-06-15T13:50:51.275842","status":"completed"},"tags":[]},"outputs":[],"source":["class Transformer(keras.Model):\n","    def __init__(\n","        self,\n","        num_hid=64,\n","        num_head=2,\n","        num_feed_forward=128,\n","        source_maxlen=100,\n","        target_maxlen=100,\n","        num_layers_enc=4,\n","        num_layers_dec=1,\n","        num_classes=10,\n","    ):\n","        super().__init__()\n","        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n","        self.num_layers_enc = num_layers_enc\n","        self.num_layers_dec = num_layers_dec\n","        self.target_maxlen = target_maxlen\n","        self.num_classes = num_classes\n","\n","        self.enc_input = SpeechFeatureEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n","        self.dec_input = TokenEmbedding(\n","            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n","        )\n","\n","        self.encoder = keras.Sequential(\n","            [self.enc_input]\n","            + [\n","                TransformerEncoder(num_hid, num_head, num_feed_forward)\n","                for _ in range(num_layers_enc)\n","            ]\n","        )\n","\n","        for i in range(num_layers_dec):\n","            setattr(\n","                self,\n","                f\"dec_layer_{i}\",\n","                TransformerDecoder(num_hid, num_head, num_feed_forward),\n","            )\n","\n","        self.classifier = layers.Dense(num_classes)\n","\n","    def decode(self, enc_out, target):\n","        y = self.dec_input(target)\n","        for i in range(self.num_layers_dec):\n","            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y)\n","        return y\n","\n","    def call(self, inputs):\n","        source = inputs[0]\n","        target = inputs[1]\n","        x = self.encoder(source)\n","        y = self.decode(x, target)\n","        return self.classifier(y)\n","\n","    @property\n","    def metrics(self):\n","        return [self.loss_metric]\n","\n","    def train_step(self, batch):\n","        \"\"\"Processes one batch inside model.fit().\"\"\"\n","        source = batch[\"source\"]\n","        target = batch[\"target\"]\n","        dec_input = target[:, :-1]\n","        dec_target = target[:, 1:]\n","        with tf.GradientTape() as tape:\n","            preds = self([source, dec_input])\n","            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n","            mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n","            loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n","        trainable_vars = self.trainable_variables\n","        gradients = tape.gradient(loss, trainable_vars)\n","        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n","        self.loss_metric.update_state(loss)\n","        return {\"loss\": self.loss_metric.result()}\n","\n","    def test_step(self, batch):\n","        source = batch[\"source\"]\n","        target = batch[\"target\"]\n","        dec_input = target[:, :-1]\n","        dec_target = target[:, 1:]\n","        preds = self([source, dec_input])\n","        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n","        mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n","        loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n","        self.loss_metric.update_state(loss)\n","        return {\"loss\": self.loss_metric.result()}\n","\n","    def generate(self, source, target_start_token_idx):\n","        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n","        bs = tf.shape(source)[0]\n","        enc = self.encoder(source)\n","        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n","        dec_logits = []\n","        for i in range(self.target_maxlen - 1):\n","            dec_out = self.decode(enc, dec_input)\n","            logits = self.classifier(dec_out)\n","            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n","            last_logit = tf.expand_dims(logits[:, -1], axis=-1)\n","            dec_logits.append(last_logit)\n","            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n","        return dec_input"]},{"cell_type":"markdown","id":"ddbb7346","metadata":{"papermill":{"duration":0.005878,"end_time":"2024-06-15T13:50:51.315386","exception":false,"start_time":"2024-06-15T13:50:51.309508","status":"completed"},"tags":[]},"source":["# Download the dataset"]},{"cell_type":"code","execution_count":7,"id":"175cd368","metadata":{"execution":{"iopub.execute_input":"2024-06-15T13:50:51.328418Z","iopub.status.busy":"2024-06-15T13:50:51.328149Z","iopub.status.idle":"2024-06-15T13:57:10.780895Z","shell.execute_reply":"2024-06-15T13:57:10.780016Z"},"papermill":{"duration":379.462044,"end_time":"2024-06-15T13:57:10.783367","exception":false,"start_time":"2024-06-15T13:50:51.321323","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n","2748572632/2748572632 [==============================] - 37s 0us/step\n"]}],"source":["keras.utils.get_file(\n","    os.path.join(os.getcwd(), \"data.tar.gz\"),\n","    \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\",\n","    extract=True,\n","    archive_format=\"tar\",\n","    cache_dir=\".\",\n",")\n","\n","\n","saveto = \"./datasets/LJSpeech-1.1\"\n","wavs = glob(\"{}/**/*.wav\".format(saveto), recursive=True)\n","\n","id_to_text = {}\n","with open(os.path.join(saveto, \"metadata.csv\"), encoding=\"utf-8\") as f:\n","    for line in f:\n","        id = line.strip().split(\"|\")[0]\n","        text = line.strip().split(\"|\")[2]\n","        id_to_text[id] = text\n","\n","\n","def get_data(wavs, id_to_text, maxlen=50):\n","    \"\"\" returns mapping of audio paths and transcription texts \"\"\"\n","    data = []\n","    for w in wavs:\n","        id = w.split(\"/\")[-1].split(\".\")[0]\n","        if len(id_to_text[id]) < maxlen:\n","            data.append({\"audio\": w, \"text\": id_to_text[id]})\n","    return data"]},{"cell_type":"markdown","id":"5e7c122e","metadata":{"papermill":{"duration":0.049365,"end_time":"2024-06-15T13:57:10.885172","exception":false,"start_time":"2024-06-15T13:57:10.835807","status":"completed"},"tags":[]},"source":["# Preprocess the dataset"]},{"cell_type":"code","execution_count":8,"id":"c7f3ae7d","metadata":{"execution":{"iopub.execute_input":"2024-06-15T13:57:10.986995Z","iopub.status.busy":"2024-06-15T13:57:10.986661Z","iopub.status.idle":"2024-06-15T13:57:23.382793Z","shell.execute_reply":"2024-06-15T13:57:23.382Z"},"papermill":{"duration":12.450353,"end_time":"2024-06-15T13:57:23.385383","exception":false,"start_time":"2024-06-15T13:57:10.93503","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["vocab size 34\n"]}],"source":["class VectorizeChar:\n","    def __init__(self, max_len=50):\n","        self.vocab = (\n","            [\"-\", \"#\", \"<\", \">\"]\n","            + [chr(i + 96) for i in range(1, 27)]\n","            + [\" \", \".\", \",\", \"?\"]\n","        )\n","        self.max_len = max_len\n","        self.char_to_idx = {}\n","        for i, ch in enumerate(self.vocab):\n","            self.char_to_idx[ch] = i\n","\n","    def __call__(self, text):\n","        text = text.lower()\n","        text = text[: self.max_len - 2]\n","        text = \"<\" + text + \">\"\n","        pad_len = self.max_len - len(text)\n","        return [self.char_to_idx.get(ch, 1) for ch in text] + [0] * pad_len\n","\n","    def get_vocabulary(self):\n","        return self.vocab\n","\n","\n","max_target_len = 200  # all transcripts in out data are < 200 characters\n","data = get_data(wavs, id_to_text, max_target_len)\n","vectorizer = VectorizeChar(max_target_len)\n","print(\"vocab size\", len(vectorizer.get_vocabulary()))\n","\n","\n","def create_text_ds(data):\n","    texts = [_[\"text\"] for _ in data]\n","    text_ds = [vectorizer(t) for t in texts]\n","    text_ds = tf.data.Dataset.from_tensor_slices(text_ds)\n","    return text_ds\n","\n","\n","def path_to_audio(path):\n","    # spectrogram using stft\n","    audio = tf.io.read_file(path)\n","    audio, _ = tf.audio.decode_wav(audio, 1)\n","    audio = tf.squeeze(audio, axis=-1)\n","    stfts = tf.signal.stft(audio, frame_length=200, frame_step=80, fft_length=256)\n","    x = tf.math.pow(tf.abs(stfts), 0.5)\n","    # normalisation\n","    means = tf.math.reduce_mean(x, 1, keepdims=True)\n","    stddevs = tf.math.reduce_std(x, 1, keepdims=True)\n","    x = (x - means) / stddevs\n","    audio_len = tf.shape(x)[0]\n","    # padding to 10 seconds\n","    pad_len = 2754\n","    paddings = tf.constant([[0, pad_len], [0, 0]])\n","    x = tf.pad(x, paddings, \"CONSTANT\")[:pad_len, :]\n","    return x\n","\n","\n","def create_audio_ds(data):\n","    flist = [_[\"audio\"] for _ in data]\n","    audio_ds = tf.data.Dataset.from_tensor_slices(flist)\n","    audio_ds = audio_ds.map(\n","        path_to_audio, num_parallel_calls=tf.data.AUTOTUNE\n","    )\n","    return audio_ds\n","\n","\n","def create_tf_dataset(data, bs=4):\n","    audio_ds = create_audio_ds(data)\n","    text_ds = create_text_ds(data)\n","    ds = tf.data.Dataset.zip((audio_ds, text_ds))\n","    ds = ds.map(lambda x, y: {\"source\": x, \"target\": y})\n","    ds = ds.batch(bs)\n","    ds = ds.prefetch(tf.data.AUTOTUNE)\n","    return ds\n","\n","\n","split = int(len(data) * 0.99)\n","train_data = data[:split]\n","test_data = data[split:]\n","ds = create_tf_dataset(train_data, bs=64)\n","val_ds = create_tf_dataset(test_data, bs=4)"]},{"cell_type":"markdown","id":"960af02e","metadata":{"papermill":{"duration":0.050895,"end_time":"2024-06-15T13:57:23.487281","exception":false,"start_time":"2024-06-15T13:57:23.436386","status":"completed"},"tags":[]},"source":["# Callbacks to display predictions"]},{"cell_type":"code","execution_count":9,"id":"e0272127","metadata":{"execution":{"iopub.execute_input":"2024-06-15T13:57:23.58893Z","iopub.status.busy":"2024-06-15T13:57:23.588614Z","iopub.status.idle":"2024-06-15T13:57:23.597825Z","shell.execute_reply":"2024-06-15T13:57:23.597056Z"},"papermill":{"duration":0.062111,"end_time":"2024-06-15T13:57:23.599802","exception":false,"start_time":"2024-06-15T13:57:23.537691","status":"completed"},"tags":[]},"outputs":[],"source":["class DisplayOutputs(keras.callbacks.Callback):\n","    def __init__(\n","        self, batch, idx_to_token, target_start_token_idx=27, target_end_token_idx=28\n","    ):\n","        \"\"\"Displays a batch of outputs after every epoch\n","\n","        Args:\n","            batch: A test batch containing the keys \"source\" and \"target\"\n","            idx_to_token: A List containing the vocabulary tokens corresponding to their indices\n","            target_start_token_idx: A start token index in the target vocabulary\n","            target_end_token_idx: An end token index in the target vocabulary\n","        \"\"\"\n","        self.batch = batch\n","        self.target_start_token_idx = target_start_token_idx\n","        self.target_end_token_idx = target_end_token_idx\n","        self.idx_to_char = idx_to_token\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        if epoch % 5 != 0:\n","            return\n","        source = self.batch[\"source\"]\n","        target = self.batch[\"target\"].numpy()\n","        bs = tf.shape(source)[0]\n","        preds = self.model.generate(source, self.target_start_token_idx)\n","        preds = preds.numpy()\n","        for i in range(bs):\n","            target_text = \"\".join([self.idx_to_char[_] for _ in target[i, :]])\n","            prediction = \"\"\n","            for idx in preds[i, :]:\n","                prediction += self.idx_to_char[idx]\n","                if idx == self.target_end_token_idx:\n","                    break\n","            print(f\"target:     {target_text.replace('-','')}\")\n","            print(f\"prediction: {prediction}\\n\")"]},{"cell_type":"markdown","id":"659223d7","metadata":{"papermill":{"duration":0.049445,"end_time":"2024-06-15T13:57:23.699297","exception":false,"start_time":"2024-06-15T13:57:23.649852","status":"completed"},"tags":[]},"source":["# Learning rate schedule"]},{"cell_type":"code","execution_count":10,"id":"ac9bbe52","metadata":{"execution":{"iopub.execute_input":"2024-06-15T13:57:23.804172Z","iopub.status.busy":"2024-06-15T13:57:23.803847Z","iopub.status.idle":"2024-06-15T13:57:23.812757Z","shell.execute_reply":"2024-06-15T13:57:23.811959Z"},"papermill":{"duration":0.064225,"end_time":"2024-06-15T13:57:23.814851","exception":false,"start_time":"2024-06-15T13:57:23.750626","status":"completed"},"tags":[]},"outputs":[],"source":["class CustomSchedule(keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(\n","        self,\n","        init_lr=0.00001,\n","        lr_after_warmup=0.001,\n","        final_lr=0.00001,\n","        warmup_epochs=15,\n","        decay_epochs=85,\n","        steps_per_epoch=203,\n","    ):\n","        super().__init__()\n","        self.init_lr = init_lr\n","        self.lr_after_warmup = lr_after_warmup\n","        self.final_lr = final_lr\n","        self.warmup_epochs = warmup_epochs\n","        self.decay_epochs = decay_epochs\n","        self.steps_per_epoch = steps_per_epoch\n","\n","    def calculate_lr(self, epoch):\n","        \"\"\" linear warm up - linear decay \"\"\"\n","        warmup_lr = (\n","            self.init_lr\n","            + ((self.lr_after_warmup - self.init_lr) / (self.warmup_epochs - 1)) * epoch\n","        )\n","        decay_lr = tf.math.maximum(\n","            self.final_lr,\n","            self.lr_after_warmup\n","            - (epoch - self.warmup_epochs)\n","            * (self.lr_after_warmup - self.final_lr)\n","            / self.decay_epochs,\n","        )\n","        return tf.math.minimum(warmup_lr, decay_lr)\n","\n","    def __call__(self, step):\n","        epoch = step // self.steps_per_epoch\n","        return self.calculate_lr(epoch)"]},{"cell_type":"markdown","id":"f54dce64","metadata":{"papermill":{"duration":0.050025,"end_time":"2024-06-15T13:57:23.917328","exception":false,"start_time":"2024-06-15T13:57:23.867303","status":"completed"},"tags":[]},"source":["# Create & train the end-to-end model"]},{"cell_type":"code","execution_count":11,"id":"e18640a5","metadata":{"execution":{"iopub.execute_input":"2024-06-15T13:57:24.021887Z","iopub.status.busy":"2024-06-15T13:57:24.021564Z","iopub.status.idle":"2024-06-15T13:59:40.00201Z","shell.execute_reply":"2024-06-15T13:59:40.001145Z"},"papermill":{"duration":136.034503,"end_time":"2024-06-15T13:59:40.004383","exception":false,"start_time":"2024-06-15T13:57:23.96988","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["203/203 [==============================] - ETA: 0s - loss: 1.4236target:     <delgado testified that oswald was, quote, a complete believer that our way of government was not quite right, end quote.>\n","prediction: <the as the the the the the are are the the the the the as the the the the the the the the an are the t the the an the athe the the the the te the the and there on ther thesthese the o tendene cond t \n","\n","target:     <manning, when sentence of death was passed on him, said nothing#>\n","prediction: <the as the the the the the are the the the the the the as the the the the the the the the the the the the the an the there the the there the there therenere s the was wantherese the o wandene cond t \n","\n","target:     <oswald met disappointments there just as he had in the past. at the outset the soviets told him that he could not remain.>\n","prediction: <the as the the the the the are are the the the the the as the the the the the the the the an are the t the the an the athe the the the the te the the and there on ther thesthese the o tendene cond t \n","\n","target:     <thomas dobson, on twentysecond august, seventeen ninetynine, for one shilling, with costs of eight shillings, ten pence.>\n","prediction: <the as the the the the the are are the the the the the as the the the the the the the the an are the t the the an the athe the the the the te the the and there on ther thesthese the o tendene cond t \n","\n","203/203 [==============================] - 136s 537ms/step - loss: 1.4236 - val_loss: 1.2823\n"]}],"source":["batch = next(iter(val_ds))\n","\n","# The vocabulary to convert predicted indices into characters\n","idx_to_char = vectorizer.get_vocabulary()\n","display_cb = DisplayOutputs(\n","    batch, idx_to_char, target_start_token_idx=2, target_end_token_idx=3\n",")  # set the arguments as per vocabulary index for '<' and '>'\n","\n","model = Transformer(\n","    num_hid=200,\n","    num_head=2,\n","    num_feed_forward=400,\n","    target_maxlen=max_target_len,\n","    num_layers_enc=4,\n","    num_layers_dec=1,\n","    num_classes=34,\n",")\n","loss_fn = tf.keras.losses.CategoricalCrossentropy(\n","    from_logits=True, label_smoothing=0.1,\n",")\n","\n","learning_rate = CustomSchedule(\n","    init_lr=0.00001,\n","    lr_after_warmup=0.001,\n","    final_lr=0.00001,\n","    warmup_epochs=15,\n","    decay_epochs=85,\n","    steps_per_epoch=len(ds)\n",")\n","\n","learning_rate = 0.0001\n","optimizer = keras.optimizers.Adam(learning_rate)\n","\n","model.compile(optimizer=optimizer, loss=loss_fn)\n","\n","history = model.fit(ds, validation_data=val_ds, callbacks=[display_cb], epochs=1)"]},{"cell_type":"code","execution_count":12,"id":"b5dcf290","metadata":{"execution":{"iopub.execute_input":"2024-06-15T13:59:40.139933Z","iopub.status.busy":"2024-06-15T13:59:40.139617Z","iopub.status.idle":"2024-06-15T13:59:40.173662Z","shell.execute_reply":"2024-06-15T13:59:40.172689Z"},"papermill":{"duration":0.103081,"end_time":"2024-06-15T13:59:40.175543","exception":false,"start_time":"2024-06-15T13:59:40.072462","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"transformer\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," speech_feature_embedding (S  (None, None, 200)        1164400   \n"," peechFeatureEmbedding)                                          \n","                                                                 \n"," token_embedding (TokenEmbed  multiple                 46800     \n"," ding)                                                           \n","                                                                 \n"," sequential_4 (Sequential)   (None, None, 200)         3095600   \n","                                                                 \n"," transformer_decoder (Transf  multiple                 804600    \n"," ormerDecoder)                                                   \n","                                                                 \n"," dense_10 (Dense)            multiple                  6834      \n","                                                                 \n","=================================================================\n","Total params: 3,953,836\n","Trainable params: 3,953,834\n","Non-trainable params: 2\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","id":"73a898fa","metadata":{"papermill":{"duration":0.068336,"end_time":"2024-06-15T13:59:40.311701","exception":false,"start_time":"2024-06-15T13:59:40.243365","status":"completed"},"tags":[]},"source":["# Save and Load the model"]},{"cell_type":"code","execution_count":13,"id":"80d2db8a","metadata":{"execution":{"iopub.execute_input":"2024-06-15T13:59:40.450793Z","iopub.status.busy":"2024-06-15T13:59:40.450418Z","iopub.status.idle":"2024-06-15T13:59:53.589652Z","shell.execute_reply":"2024-06-15T13:59:53.588811Z"},"papermill":{"duration":13.211994,"end_time":"2024-06-15T13:59:53.592162","exception":false,"start_time":"2024-06-15T13:59:40.380168","status":"completed"},"tags":[]},"outputs":[],"source":["# Save the model\n","model.save('transformer_model')"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30528,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":566.187217,"end_time":"2024-06-15T13:59:56.860713","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-06-15T13:50:30.673496","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}