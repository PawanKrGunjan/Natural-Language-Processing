{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a31bd7",
   "metadata": {
    "papermill": {
     "duration": 0.008208,
     "end_time": "2023-08-14T07:03:50.096133",
     "exception": false,
     "start_time": "2023-08-14T07:03:50.087925",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c0abf3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:03:50.113923Z",
     "iopub.status.busy": "2023-08-14T07:03:50.113291Z",
     "iopub.status.idle": "2023-08-14T07:03:59.025580Z",
     "shell.execute_reply": "2023-08-14T07:03:59.024334Z"
    },
    "papermill": {
     "duration": 8.92445,
     "end_time": "2023-08-14T07:03:59.028613",
     "exception": false,
     "start_time": "2023-08-14T07:03:50.104163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49b6d6d",
   "metadata": {
    "papermill": {
     "duration": 0.011364,
     "end_time": "2023-08-14T07:03:59.052072",
     "exception": false,
     "start_time": "2023-08-14T07:03:59.040708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define the Transformer Input Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b29c79b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:03:59.076778Z",
     "iopub.status.busy": "2023-08-14T07:03:59.076118Z",
     "iopub.status.idle": "2023-08-14T07:03:59.085452Z",
     "shell.execute_reply": "2023-08-14T07:03:59.084197Z"
    },
    "papermill": {
     "duration": 0.025185,
     "end_time": "2023-08-14T07:03:59.088725",
     "exception": false,
     "start_time": "2023-08-14T07:03:59.063540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TokenEmbedding(layers.Layer):\n",
    "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n",
    "        super().__init__()\n",
    "        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        x = self.emb(x)\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b31411",
   "metadata": {
    "papermill": {
     "duration": 0.011485,
     "end_time": "2023-08-14T07:03:59.111727",
     "exception": false,
     "start_time": "2023-08-14T07:03:59.100242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. **Class Definition (`TokenEmbedding`):**\n",
    "   - A custom Keras layer is defined, named `TokenEmbedding`.\n",
    "   - The layer is designed to create token embeddings for input sequences in a transformer model.\n",
    "\n",
    "2. **`__init__` Method:**\n",
    "   - The constructor method initializes the layer's attributes when an instance is created.\n",
    "   - `num_vocab`: Number of unique tokens in the vocabulary. Default is 1000.\n",
    "   - `maxlen`: Maximum sequence length. Default is 100.\n",
    "   - `num_hid`: Number of dimensions for the token embeddings. Default is 64.\n",
    "\n",
    "3. **Embedding Layers Initialization:**\n",
    "   - Inside the constructor, two embedding layers are initialized:\n",
    "     - `self.emb`: An embedding layer to create token embeddings based on the vocabulary size (`num_vocab`) and embedding dimensions (`num_hid`).\n",
    "     - `self.pos_emb`: An embedding layer to create positional embeddings based on the sequence length (`maxlen`) and embedding dimensions (`num_hid`).\n",
    "\n",
    "4. **`call` Method:**\n",
    "   - The `call` method defines the forward pass of the layer, where the actual computations are performed.\n",
    "   - `x` is the input tensor representing a sequence of token indices.\n",
    "\n",
    "5. **Token Embeddings:**\n",
    "   - `x = self.emb(x)`: The input token indices are passed through the embedding layer to create token embeddings. Each token index is mapped to a continuous vector representation.\n",
    "\n",
    "6. **Positional Embeddings:**\n",
    "   - `maxlen = tf.shape(x)[-1]`: Calculates the maximum sequence length based on the shape of the input tensor `x`.\n",
    "   - `positions = tf.range(start=0, limit=maxlen, delta=1)`: Creates a sequence of integers from 0 to `maxlen - 1` to represent positions in the sequence.\n",
    "   - `positions = self.pos_emb(positions)`: Passes the position indices through the positional embedding layer to create positional embeddings.\n",
    "\n",
    "7. **Combining Token and Positional Embeddings:**\n",
    "   - `return x + positions`: Adds the token embeddings and positional embeddings element-wise. This is a common step in transformer models to inject positional information into the token embeddings.\n",
    "\n",
    "`TokenEmbedding` layer initializes token embeddings using an embedding layer and positional embeddings using another embedding layer. The `call` method combines these embeddings to provide enriched token representations that include both token-specific and positional information. This layer can be used as part of a transformer model's input layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e75ea2b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:03:59.136336Z",
     "iopub.status.busy": "2023-08-14T07:03:59.135724Z",
     "iopub.status.idle": "2023-08-14T07:03:59.145881Z",
     "shell.execute_reply": "2023-08-14T07:03:59.145092Z"
    },
    "papermill": {
     "duration": 0.025129,
     "end_time": "2023-08-14T07:03:59.148399",
     "exception": false,
     "start_time": "2023-08-14T07:03:59.123270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SpeechFeatureEmbedding(layers.Layer):\n",
    "    def __init__(self, num_hid=64, maxlen=100):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv1D(\n",
    "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2 = tf.keras.layers.Conv1D(\n",
    "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3 = tf.keras.layers.Conv1D(\n",
    "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return self.conv3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1d31bb",
   "metadata": {
    "papermill": {
     "duration": 0.011667,
     "end_time": "2023-08-14T07:03:59.171998",
     "exception": false,
     "start_time": "2023-08-14T07:03:59.160331",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. **Class Definition (`SpeechFeatureEmbedding`):**\n",
    "   - This is a custom Keras layer designed to process speech features and convert them into embeddings suitable for a transformer input.\n",
    "\n",
    "2. **`__init__` Method:**\n",
    "   - The constructor method initializes the layer's attributes when an instance is created.\n",
    "   - `num_hid`: Number of filters or hidden units in each convolutional layer. Default is 64.\n",
    "   - `maxlen`: Maximum sequence length (number of time steps in the speech features). Default is 100.\n",
    "\n",
    "3. **Convolutional Layers Initialization:**\n",
    "   - Three 1D convolutional layers (`conv1`, `conv2`, and `conv3`) are initialized:\n",
    "     - Each convolutional layer performs a 1D convolution operation on the input data.\n",
    "     - `num_hid` filters are used for each convolutional layer.\n",
    "     - A filter size of 11 is specified for each convolutional layer.\n",
    "     - The `strides` parameter is set to 2, which means the convolutional operation will skip every other input value.\n",
    "     - Padding is set to \"same,\" which maintains the input shape after convolution.\n",
    "     - The `activation` function is set to ReLU (Rectified Linear Unit), which introduces non-linearity.\n",
    "\n",
    "4. **`call` Method:**\n",
    "   - The `call` method defines the forward pass of the layer, where the actual computations are performed.\n",
    "   - `x` is the input tensor representing speech features, often in the form of spectrogram frames.\n",
    "\n",
    "5. **Convolutional Operations:**\n",
    "   - `x = self.conv1(x)`: Applies the first convolutional layer to the input `x`.\n",
    "   - `x = self.conv2(x)`: Applies the second convolutional layer to the result of the previous convolution.\n",
    "   - The convolutional operations with different filters and strides help capture different levels of information from the input features.\n",
    "\n",
    "6. **Final Convolution and Output:**\n",
    "   - `return self.conv3(x)`: Applies the third convolutional layer to the result of the previous convolutional operations. This produces the final output of the layer.\n",
    "\n",
    "`SpeechFeatureEmbedding` layer uses three 1D convolutional layers to process speech features and create embeddings that can be used as input to a transformer model. The layer captures different patterns and representations in the speech data at various levels of abstraction through convolutional operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7117094",
   "metadata": {
    "papermill": {
     "duration": 0.011524,
     "end_time": "2023-08-14T07:03:59.195618",
     "exception": false,
     "start_time": "2023-08-14T07:03:59.184094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transformer Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4f452f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:03:59.221470Z",
     "iopub.status.busy": "2023-08-14T07:03:59.221118Z",
     "iopub.status.idle": "2023-08-14T07:03:59.233495Z",
     "shell.execute_reply": "2023-08-14T07:03:59.232705Z"
    },
    "papermill": {
     "duration": 0.028176,
     "end_time": "2023-08-14T07:03:59.236241",
     "exception": false,
     "start_time": "2023-08-14T07:03:59.208065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d7c862",
   "metadata": {
    "papermill": {
     "duration": 0.011385,
     "end_time": "2023-08-14T07:03:59.259258",
     "exception": false,
     "start_time": "2023-08-14T07:03:59.247873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. **Class Definition (`TransformerEncoder`):**\n",
    "   - This class represents a single layer of the Transformer encoder.\n",
    "\n",
    "2. **`__init__` Method:**\n",
    "   - The constructor initializes the layer's attributes when an instance is created.\n",
    "   - `embed_dim`: The dimension of the input and output embeddings.\n",
    "   - `num_heads`: The number of attention heads in the multi-head attention mechanism.\n",
    "   - `feed_forward_dim`: The dimension of the feed-forward neural network within the layer.\n",
    "   - `rate`: Dropout rate, which controls the amount of dropout regularization applied to the layer's outputs.\n",
    "\n",
    "3. **Multi-Head Attention (`self.att`):**\n",
    "   - Initializes a multi-head attention layer using the specified number of heads and embedding dimension (`embed_dim`).\n",
    "\n",
    "4. **Feed-Forward Network (`self.ffn`):**\n",
    "   - Initializes a feed-forward neural network (FFN) composed of two dense layers:\n",
    "     - The first dense layer has `feed_forward_dim` units and uses ReLU activation.\n",
    "     - The second dense layer has `embed_dim` units.\n",
    "\n",
    "5. **Layer Normalization (`self.layernorm1` and `self.layernorm2`):**\n",
    "   - Initializes two layer normalization layers, each with a small epsilon value to prevent division by zero.\n",
    "\n",
    "6. **Dropout (`self.dropout1` and `self.dropout2`):**\n",
    "   - Initializes two dropout layers with the specified dropout rate (`rate`).\n",
    "\n",
    "7. **`call` Method:**\n",
    "   - The `call` method defines the forward pass of the layer, where the actual computations are performed.\n",
    "   - `inputs`: The input tensor.\n",
    "   - `training`: A boolean flag indicating whether the model is in training mode.\n",
    "\n",
    "8. **Multi-Head Attention Forward Pass:**\n",
    "   - `attn_output = self.att(inputs, inputs)`: Applies the multi-head attention mechanism to the input.\n",
    "   - `attn_output = self.dropout1(attn_output, training=training)`: Applies dropout to the attention output.\n",
    "\n",
    "9. **Residual Connection and Layer Normalization (`out1`):**\n",
    "   - `out1 = self.layernorm1(inputs + attn_output)`: Adds the attention output to the input and applies layer normalization.\n",
    "\n",
    "10. **Feed-Forward Network Forward Pass:**\n",
    "    - `ffn_output = self.ffn(out1)`: Passes the output of the attention layer through the feed-forward network.\n",
    "    - `ffn_output = self.dropout2(ffn_output, training=training)`: Applies dropout to the FFN output.\n",
    "\n",
    "11. **Residual Connection and Layer Normalization (`return` statement):**\n",
    "    - `return self.layernorm2(out1 + ffn_output)`: Adds the FFN output to the previous output and applies layer normalization.\n",
    "    - The final result of the layer represents the output of the TransformerEncoder.\n",
    "\n",
    "`TransformerEncoder` layer implements a single block of a Transformer encoder. It includes a multi-head attention mechanism followed by a feed-forward network, with residual connections, layer normalization, and dropout applied at appropriate points in the computation. This layer can be stacked multiple times to form the complete Transformer encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcbba2f",
   "metadata": {
    "papermill": {
     "duration": 0.011873,
     "end_time": "2023-08-14T07:03:59.283194",
     "exception": false,
     "start_time": "2023-08-14T07:03:59.271321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transformer Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0afec3bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:03:59.307710Z",
     "iopub.status.busy": "2023-08-14T07:03:59.307356Z",
     "iopub.status.idle": "2023-08-14T07:03:59.327093Z",
     "shell.execute_reply": "2023-08-14T07:03:59.326305Z"
    },
    "papermill": {
     "duration": 0.035089,
     "end_time": "2023-08-14T07:03:59.329797",
     "exception": false,
     "start_time": "2023-08-14T07:03:59.294708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.self_att = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.self_dropout = layers.Dropout(0.5)\n",
    "        self.enc_dropout = layers.Dropout(0.1)\n",
    "        self.ffn_dropout = layers.Dropout(0.1)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n",
    "        \"\"\"Masks the upper half of the dot product matrix in self attention.\n",
    "\n",
    "        This prevents flow of information from future tokens to current token.\n",
    "        1's in the lower triangle, counting from the lower right corner.\n",
    "        \"\"\"\n",
    "        i = tf.range(n_dest)[:, None]\n",
    "        j = tf.range(n_src)\n",
    "        m = i >= j - n_src + n_dest\n",
    "        mask = tf.cast(m, dtype)\n",
    "        mask = tf.reshape(mask, [1, n_dest, n_src])\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, enc_out, target):\n",
    "        input_shape = tf.shape(target)\n",
    "        batch_size = input_shape[0]\n",
    "        seq_len = input_shape[1]\n",
    "        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
    "        target_att = self.self_att(target, target, attention_mask=causal_mask)\n",
    "        target_norm = self.layernorm1(target + self.self_dropout(target_att))\n",
    "        enc_out = self.enc_att(target_norm, enc_out)\n",
    "        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out) + target_norm)\n",
    "        ffn_out = self.ffn(enc_out_norm)\n",
    "        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out))\n",
    "        return ffn_out_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07bc820",
   "metadata": {
    "papermill": {
     "duration": 0.013273,
     "end_time": "2023-08-14T07:03:59.355212",
     "exception": false,
     "start_time": "2023-08-14T07:03:59.341939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. **Class Definition (`TransformerDecoder`):**\n",
    "   - This class represents a single layer of the Transformer decoder.\n",
    "\n",
    "2. **`__init__` Method:**\n",
    "   - Initializes the layer's attributes when an instance is created.\n",
    "   - `embed_dim`: The dimension of the input and output embeddings.\n",
    "   - `num_heads`: The number of attention heads in the multi-head attention mechanisms.\n",
    "   - `feed_forward_dim`: The dimension of the feed-forward neural network within the layer.\n",
    "   - `dropout_rate`: Dropout rate for various dropout layers.\n",
    "\n",
    "3. **Layer Normalization (`self.layernorm1`, `self.layernorm2`, `self.layernorm3`):**\n",
    "   - Initializes three layer normalization layers, each with a small epsilon value to prevent division by zero.\n",
    "\n",
    "4. **Multi-Head Self-Attention (`self.self_att`):**\n",
    "   - Initializes a multi-head self-attention layer for the decoder's self-attention mechanism.\n",
    "\n",
    "5. **Multi-Head Encoder-Decoder Attention (`self.enc_att`):**\n",
    "   - Initializes a multi-head attention layer for the encoder-decoder attention mechanism.\n",
    "\n",
    "6. **Dropout (`self.self_dropout`, `self.enc_dropout`, `self.ffn_dropout`):**\n",
    "   - Initializes dropout layers with the specified dropout rates for various components.\n",
    "\n",
    "7. **Feed-Forward Network (`self.ffn`):**\n",
    "   - Initializes a feed-forward neural network (FFN) composed of two dense layers:\n",
    "     - The first dense layer has `feed_forward_dim` units and uses ReLU activation.\n",
    "     - The second dense layer has `embed_dim` units.\n",
    "\n",
    "8. **`causal_attention_mask` Method:**\n",
    "   - Defines a function to create a causal attention mask that masks the upper half of the dot product matrix to prevent future information flow.\n",
    "\n",
    "9. **`call` Method:**\n",
    "   - Defines the forward pass of the layer where the actual computations are performed.\n",
    "   - `enc_out`: The output of the encoder.\n",
    "   - `target`: The input to the decoder.\n",
    "\n",
    "10. **Creating Causal Attention Mask:**\n",
    "    - `causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)`: Creates a causal attention mask.\n",
    "\n",
    "11. **Self-Attention for Decoder Input (`target_att`):**\n",
    "    - `target_att = self.self_att(target, target, attention_mask=causal_mask)`: Applies self-attention to the decoder input with the causal attention mask.\n",
    "    - `target_norm = self.layernorm1(target + self.self_dropout(target_att))`: Applies layer normalization and dropout to the self-attention output.\n",
    "\n",
    "12. **Encoder-Decoder Attention (`enc_out`):**\n",
    "    - `enc_out = self.enc_att(target_norm, enc_out)`: Applies encoder-decoder attention by attending over the encoder output using the decoder input.\n",
    "    - `enc_out_norm = self.layernorm2(self.enc_dropout(enc_out) + target_norm)`: Applies layer normalization and dropout to the encoder-decoder attention output.\n",
    "\n",
    "13. **Feed-Forward Network (`ffn_out`):**\n",
    "    - `ffn_out = self.ffn(enc_out_norm)`: Passes the output of the encoder-decoder attention through the feed-forward network.\n",
    "\n",
    "14. **Final Layer Normalization (`ffn_out_norm`):**\n",
    "    - `ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out))`: Applies layer normalization and dropout to the output of the feed-forward network and adds it to the output of the encoder-decoder attention.\n",
    "\n",
    "17. **Returning the Output (`return ffn_out_norm)`:**\n",
    "    - The `call` method returns the final output of the decoder layer after passing it through the multi-head self-attention, encoder-decoder attention, feed-forward network, and applying normalization and dropout.\n",
    "\n",
    "This `TransformerDecoder` layer is one component of the Transformer model's decoder stack, responsible for processing the decoder inputs and producing contextualized outputs based on self-attention and attention to the encoder outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e310c46f",
   "metadata": {
    "papermill": {
     "duration": 0.007914,
     "end_time": "2023-08-14T07:03:59.371757",
     "exception": false,
     "start_time": "2023-08-14T07:03:59.363843",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Complete the Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd02495e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:03:59.390228Z",
     "iopub.status.busy": "2023-08-14T07:03:59.389952Z",
     "iopub.status.idle": "2023-08-14T07:03:59.409818Z",
     "shell.execute_reply": "2023-08-14T07:03:59.408833Z"
    },
    "papermill": {
     "duration": 0.031575,
     "end_time": "2023-08-14T07:03:59.411807",
     "exception": false,
     "start_time": "2023-08-14T07:03:59.380232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_hid=64,\n",
    "        num_head=2,\n",
    "        num_feed_forward=128,\n",
    "        source_maxlen=100,\n",
    "        target_maxlen=100,\n",
    "        num_layers_enc=4,\n",
    "        num_layers_dec=1,\n",
    "        num_classes=10,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n",
    "        self.num_layers_enc = num_layers_enc\n",
    "        self.num_layers_dec = num_layers_dec\n",
    "        self.target_maxlen = target_maxlen\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.enc_input = SpeechFeatureEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n",
    "        self.dec_input = TokenEmbedding(\n",
    "            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n",
    "        )\n",
    "\n",
    "        self.encoder = keras.Sequential(\n",
    "            [self.enc_input]\n",
    "            + [\n",
    "                TransformerEncoder(num_hid, num_head, num_feed_forward)\n",
    "                for _ in range(num_layers_enc)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        for i in range(num_layers_dec):\n",
    "            setattr(\n",
    "                self,\n",
    "                f\"dec_layer_{i}\",\n",
    "                TransformerDecoder(num_hid, num_head, num_feed_forward),\n",
    "            )\n",
    "\n",
    "        self.classifier = layers.Dense(num_classes)\n",
    "\n",
    "    def decode(self, enc_out, target):\n",
    "        y = self.dec_input(target)\n",
    "        for i in range(self.num_layers_dec):\n",
    "            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y)\n",
    "        return y\n",
    "\n",
    "    def call(self, inputs):\n",
    "        source = inputs[0]\n",
    "        target = inputs[1]\n",
    "        x = self.encoder(source)\n",
    "        y = self.decode(x, target)\n",
    "        return self.classifier(y)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_metric]\n",
    "\n",
    "    def train_step(self, batch):\n",
    "        \"\"\"Processes one batch inside model.fit().\"\"\"\n",
    "        source = batch[\"source\"]\n",
    "        target = batch[\"target\"]\n",
    "        dec_input = target[:, :-1]\n",
    "        dec_target = target[:, 1:]\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = self([source, dec_input])\n",
    "            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
    "            mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
    "            loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.loss_metric.update_state(loss)\n",
    "        return {\"loss\": self.loss_metric.result()}\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        source = batch[\"source\"]\n",
    "        target = batch[\"target\"]\n",
    "        dec_input = target[:, :-1]\n",
    "        dec_target = target[:, 1:]\n",
    "        preds = self([source, dec_input])\n",
    "        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
    "        mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
    "        loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
    "        self.loss_metric.update_state(loss)\n",
    "        return {\"loss\": self.loss_metric.result()}\n",
    "\n",
    "    def generate(self, source, target_start_token_idx):\n",
    "        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n",
    "        bs = tf.shape(source)[0]\n",
    "        enc = self.encoder(source)\n",
    "        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n",
    "        dec_logits = []\n",
    "        for i in range(self.target_maxlen - 1):\n",
    "            dec_out = self.decode(enc, dec_input)\n",
    "            logits = self.classifier(dec_out)\n",
    "            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "            last_logit = tf.expand_dims(logits[:, -1], axis=-1)\n",
    "            dec_logits.append(last_logit)\n",
    "            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n",
    "        return dec_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb02a60f",
   "metadata": {
    "papermill": {
     "duration": 0.007678,
     "end_time": "2023-08-14T07:03:59.427512",
     "exception": false,
     "start_time": "2023-08-14T07:03:59.419834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. **Class Definition (`Transformer`):**\n",
    "   - The class `Transformer` inherits from `keras.Model`.\n",
    "   - It initializes hyperparameters, metrics, and various components of the Transformer model.\n",
    "\n",
    "2. **Initializer (`__init__`):**\n",
    "   - Initializes the Transformer model with hyperparameters like `num_hid`, `num_head`, `num_feed_forward`, etc.\n",
    "   - Initializes a mean metric `loss_metric` for tracking the loss during training.\n",
    "   - Sets the number of encoder and decoder layers, maximum target length, and number of classes.\n",
    "   - Creates input embedding layers for the encoder (`enc_input`) and decoder (`dec_input`).\n",
    "\n",
    "3. **Encoder Initialization (`encoder`):**\n",
    "   - Sets up the encoder using a sequence of layers, starting with the `enc_input`.\n",
    "   - It stacks multiple `TransformerEncoder` layers based on the specified `num_layers_enc`.\n",
    "\n",
    "4. **Decoder Initialization (`dec_layer_i`):**\n",
    "   - For each decoder layer, initializes a `TransformerDecoder` layer and assigns it to an attribute named `dec_layer_i`.\n",
    "\n",
    "5. **Classifier Layer (`classifier`):**\n",
    "   - Initializes a dense layer (`classifier`) for predicting class labels.\n",
    "\n",
    "6. **Decode Method (`decode`):**\n",
    "   - Takes encoder outputs (`enc_out`) and target tokens (`target`) as input.\n",
    "   - Passes the target tokens through the decoder layers sequentially to generate contextualized outputs (`y`).\n",
    "\n",
    "7. **Call Method (`call`):**\n",
    "   - Takes source and target inputs and processes them through the encoder and decoder.\n",
    "   - Returns the output of the classifier layer.\n",
    "\n",
    "8. **Metrics Property (`metrics`):**\n",
    "   - Returns the list of metrics, which includes the `loss_metric`.\n",
    "\n",
    "9. **Train Step Method (`train_step`):**\n",
    "   - Implements a custom training step to handle one batch of data.\n",
    "   - Computes the loss, gradients, applies gradients using the optimizer, and updates the loss metric.\n",
    "\n",
    "10. **Test Step Method (`test_step`):**\n",
    "   - Similar to `train_step`, but used for testing/evaluation.\n",
    "\n",
    "11. **Generate Method (`generate`):**\n",
    "   - Performs inference on a batch of source inputs using greedy decoding.\n",
    "   - Initializes the decoder input with a start token index.\n",
    "   - Iterates over each time step, decoding and generating the output sequence.\n",
    "\n",
    "Overall, this code defines a custom Transformer model for sequence-to-sequence tasks. It includes encoder and decoder stacks, customized training and testing steps, and an inference method for generating sequences using greedy decoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f1175b",
   "metadata": {
    "papermill": {
     "duration": 0.007953,
     "end_time": "2023-08-14T07:03:59.443446",
     "exception": false,
     "start_time": "2023-08-14T07:03:59.435493",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f19963d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:03:59.461752Z",
     "iopub.status.busy": "2023-08-14T07:03:59.460722Z",
     "iopub.status.idle": "2023-08-14T07:10:25.768021Z",
     "shell.execute_reply": "2023-08-14T07:10:25.766930Z"
    },
    "papermill": {
     "duration": 386.319418,
     "end_time": "2023-08-14T07:10:25.770720",
     "exception": false,
     "start_time": "2023-08-14T07:03:59.451302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
      "2748572632/2748572632 [==============================] - 28s 0us/step\n"
     ]
    }
   ],
   "source": [
    "keras.utils.get_file(\n",
    "    os.path.join(os.getcwd(), \"data.tar.gz\"),\n",
    "    \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\",\n",
    "    extract=True,\n",
    "    archive_format=\"tar\",\n",
    "    cache_dir=\".\",\n",
    ")\n",
    "\n",
    "\n",
    "saveto = \"./datasets/LJSpeech-1.1\"\n",
    "wavs = glob(\"{}/**/*.wav\".format(saveto), recursive=True)\n",
    "\n",
    "id_to_text = {}\n",
    "with open(os.path.join(saveto, \"metadata.csv\"), encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        id = line.strip().split(\"|\")[0]\n",
    "        text = line.strip().split(\"|\")[2]\n",
    "        id_to_text[id] = text\n",
    "\n",
    "\n",
    "def get_data(wavs, id_to_text, maxlen=50):\n",
    "    \"\"\" returns mapping of audio paths and transcription texts \"\"\"\n",
    "    data = []\n",
    "    for w in wavs:\n",
    "        id = w.split(\"/\")[-1].split(\".\")[0]\n",
    "        if len(id_to_text[id]) < maxlen:\n",
    "            data.append({\"audio\": w, \"text\": id_to_text[id]})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d04dafe",
   "metadata": {
    "papermill": {
     "duration": 0.058735,
     "end_time": "2023-08-14T07:10:25.880190",
     "exception": false,
     "start_time": "2023-08-14T07:10:25.821455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Certainly, I'll provide a brief explanation of the code:\n",
    "\n",
    "1. **Downloading and Extracting Data (`keras.utils.get_file`):**\n",
    "   - Downloads a compressed data file from a URL and extracts its contents.\n",
    "   - The `data.tar.gz` file is downloaded from the provided URL and extracted using the \"tar\" archive format.\n",
    "   - The extracted files are saved in the current working directory.\n",
    "\n",
    "2. **File Paths and Metadata Extraction:**\n",
    "   - Defines the `saveto` variable as the path to the extracted data directory.\n",
    "   - Uses the `glob` function to recursively search for all \".wav\" files within the `saveto` directory and its subdirectories.\n",
    "   - Creates an empty dictionary `id_to_text` to store mappings between audio file IDs and their corresponding transcription texts.\n",
    "\n",
    "3. **Parsing Metadata File (`metadata.csv`):**\n",
    "   - Opens the `metadata.csv` file in the `saveto` directory for reading, assuming it contains metadata about the audio files.\n",
    "   - Iterates through each line in the file and extracts the ID and transcription text from the pipe-separated format.\n",
    "   - Builds the `id_to_text` dictionary, mapping audio file IDs to their corresponding transcription texts.\n",
    "\n",
    "4. **Data Preparation (`get_data` Function):**\n",
    "   - Defines a function `get_data` that takes a list of audio file paths, the `id_to_text` dictionary, and an optional `maxlen` parameter.\n",
    "   - The function processes each audio file and its associated text transcription.\n",
    "   - It extracts the ID from the audio file path and checks if the length of the corresponding text is less than the specified `maxlen`.\n",
    "   - If the text length condition is met, the audio file path and text are added to the `data` list.\n",
    "   - The function returns the `data` list containing audio file-text pairs that meet the criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b18ad0",
   "metadata": {
    "papermill": {
     "duration": 0.083872,
     "end_time": "2023-08-14T07:10:26.024862",
     "exception": false,
     "start_time": "2023-08-14T07:10:25.940990",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "691baa02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:10:26.122607Z",
     "iopub.status.busy": "2023-08-14T07:10:26.122234Z",
     "iopub.status.idle": "2023-08-14T07:10:39.390185Z",
     "shell.execute_reply": "2023-08-14T07:10:39.389163Z"
    },
    "papermill": {
     "duration": 13.319682,
     "end_time": "2023-08-14T07:10:39.392719",
     "exception": false,
     "start_time": "2023-08-14T07:10:26.073037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size 34\n"
     ]
    }
   ],
   "source": [
    "class VectorizeChar:\n",
    "    def __init__(self, max_len=50):\n",
    "        self.vocab = (\n",
    "            [\"-\", \"#\", \"<\", \">\"]\n",
    "            + [chr(i + 96) for i in range(1, 27)]\n",
    "            + [\" \", \".\", \",\", \"?\"]\n",
    "        )\n",
    "        self.max_len = max_len\n",
    "        self.char_to_idx = {}\n",
    "        for i, ch in enumerate(self.vocab):\n",
    "            self.char_to_idx[ch] = i\n",
    "\n",
    "    def __call__(self, text):\n",
    "        text = text.lower()\n",
    "        text = text[: self.max_len - 2]\n",
    "        text = \"<\" + text + \">\"\n",
    "        pad_len = self.max_len - len(text)\n",
    "        return [self.char_to_idx.get(ch, 1) for ch in text] + [0] * pad_len\n",
    "\n",
    "    def get_vocabulary(self):\n",
    "        return self.vocab\n",
    "\n",
    "\n",
    "max_target_len = 200  # all transcripts in out data are < 200 characters\n",
    "data = get_data(wavs, id_to_text, max_target_len)\n",
    "vectorizer = VectorizeChar(max_target_len)\n",
    "print(\"vocab size\", len(vectorizer.get_vocabulary()))\n",
    "\n",
    "\n",
    "def create_text_ds(data):\n",
    "    texts = [_[\"text\"] for _ in data]\n",
    "    text_ds = [vectorizer(t) for t in texts]\n",
    "    text_ds = tf.data.Dataset.from_tensor_slices(text_ds)\n",
    "    return text_ds\n",
    "\n",
    "\n",
    "def path_to_audio(path):\n",
    "    # spectrogram using stft\n",
    "    audio = tf.io.read_file(path)\n",
    "    audio, _ = tf.audio.decode_wav(audio, 1)\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    stfts = tf.signal.stft(audio, frame_length=200, frame_step=80, fft_length=256)\n",
    "    x = tf.math.pow(tf.abs(stfts), 0.5)\n",
    "    # normalisation\n",
    "    means = tf.math.reduce_mean(x, 1, keepdims=True)\n",
    "    stddevs = tf.math.reduce_std(x, 1, keepdims=True)\n",
    "    x = (x - means) / stddevs\n",
    "    audio_len = tf.shape(x)[0]\n",
    "    # padding to 10 seconds\n",
    "    pad_len = 2754\n",
    "    paddings = tf.constant([[0, pad_len], [0, 0]])\n",
    "    x = tf.pad(x, paddings, \"CONSTANT\")[:pad_len, :]\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_audio_ds(data):\n",
    "    flist = [_[\"audio\"] for _ in data]\n",
    "    audio_ds = tf.data.Dataset.from_tensor_slices(flist)\n",
    "    audio_ds = audio_ds.map(\n",
    "        path_to_audio, num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    return audio_ds\n",
    "\n",
    "\n",
    "def create_tf_dataset(data, bs=4):\n",
    "    audio_ds = create_audio_ds(data)\n",
    "    text_ds = create_text_ds(data)\n",
    "    ds = tf.data.Dataset.zip((audio_ds, text_ds))\n",
    "    ds = ds.map(lambda x, y: {\"source\": x, \"target\": y})\n",
    "    ds = ds.batch(bs)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "split = int(len(data) * 0.99)\n",
    "train_data = data[:split]\n",
    "test_data = data[split:]\n",
    "ds = create_tf_dataset(train_data, bs=64)\n",
    "val_ds = create_tf_dataset(test_data, bs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5cdd2d",
   "metadata": {
    "papermill": {
     "duration": 0.048905,
     "end_time": "2023-08-14T07:10:39.489383",
     "exception": false,
     "start_time": "2023-08-14T07:10:39.440478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. **`VectorizeChar` Class:**\n",
    "   - Creates a character vectorization class.\n",
    "   - Initializes with a vocabulary that includes lowercase letters, common punctuation, and special tokens (\"<\", \">\", \"-\", \"#\").\n",
    "   - Defines the maximum text length (`max_len`) and a character-to-index mapping (`char_to_idx`) based on the vocabulary.\n",
    "\n",
    "2. **Creating the `data` List:**\n",
    "   - Calls the `get_data` function to obtain a list of audio and text data pairs.\n",
    "   - The maximum target length (`max_target_len`) is set to 200 characters.\n",
    "\n",
    "3. **Creating the Vectorizer and Vocabulary:**\n",
    "   - Initializes a `VectorizeChar` instance with the `max_target_len`.\n",
    "   - Prints the vocabulary size using the `get_vocabulary()` method of the vectorizer.\n",
    "\n",
    "4. **Creating Text Dataset (`create_text_ds`):**\n",
    "   - Extracts the texts from the `data` list.\n",
    "   - Applies the vectorizer to each text to convert it into a sequence of character indices.\n",
    "   - Creates a TensorFlow dataset from the vectorized texts.\n",
    "\n",
    "5. **Creating Audio Dataset (`create_audio_ds`):**\n",
    "   - Extracts audio file paths from the `data` list.\n",
    "   - Reads the audio data from each path using TensorFlow's audio decoding functions.\n",
    "   - Applies Short-Time Fourier Transform (STFT) to obtain spectrograms.\n",
    "   - Normalizes the spectrograms using mean and standard deviation.\n",
    "   - Pads or truncates the spectrograms to a fixed length of 2754 time steps.\n",
    "\n",
    "6. **Creating TensorFlow Dataset (`create_tf_dataset`):**\n",
    "   - Creates audio and text datasets using the previously defined functions.\n",
    "   - Zips the audio and text datasets together to create a dataset with pairs of audio and text data.\n",
    "   - Maps a function that transforms the pairs into dictionary entries with keys \"source\" and \"target\".\n",
    "   - Batches the dataset with a given batch size (`bs`).\n",
    "   - Prefetches data to optimize data loading.\n",
    "\n",
    "7. **Splitting Data and Creating Datasets for Training and Validation:**\n",
    "   - Splits the `data` list into training and validation portions.\n",
    "   - Calls `create_tf_dataset` to create TensorFlow datasets for training (`ds`) and validation (`val_ds`).\n",
    "   - The training dataset has a batch size of 64, while the validation dataset has a batch size of 4.\n",
    "\n",
    "In summary, this code prepares data for training a Transformer model. It creates vectorized text and audio datasets and forms batches suitable for training and validation. The text data is vectorized using the `VectorizeChar` class, and audio data is processed into spectrogram-like representations before being combined into TensorFlow datasets for further processing during model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39cad28",
   "metadata": {
    "papermill": {
     "duration": 0.047761,
     "end_time": "2023-08-14T07:10:39.587280",
     "exception": false,
     "start_time": "2023-08-14T07:10:39.539519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Callbacks to display predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "993ef5ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:10:39.683923Z",
     "iopub.status.busy": "2023-08-14T07:10:39.683546Z",
     "iopub.status.idle": "2023-08-14T07:10:39.693304Z",
     "shell.execute_reply": "2023-08-14T07:10:39.692253Z"
    },
    "papermill": {
     "duration": 0.060623,
     "end_time": "2023-08-14T07:10:39.695754",
     "exception": false,
     "start_time": "2023-08-14T07:10:39.635131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DisplayOutputs(keras.callbacks.Callback):\n",
    "    def __init__(\n",
    "        self, batch, idx_to_token, target_start_token_idx=27, target_end_token_idx=28\n",
    "    ):\n",
    "        \"\"\"Displays a batch of outputs after every epoch\n",
    "\n",
    "        Args:\n",
    "            batch: A test batch containing the keys \"source\" and \"target\"\n",
    "            idx_to_token: A List containing the vocabulary tokens corresponding to their indices\n",
    "            target_start_token_idx: A start token index in the target vocabulary\n",
    "            target_end_token_idx: An end token index in the target vocabulary\n",
    "        \"\"\"\n",
    "        self.batch = batch\n",
    "        self.target_start_token_idx = target_start_token_idx\n",
    "        self.target_end_token_idx = target_end_token_idx\n",
    "        self.idx_to_char = idx_to_token\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 5 != 0:\n",
    "            return\n",
    "        source = self.batch[\"source\"]\n",
    "        target = self.batch[\"target\"].numpy()\n",
    "        bs = tf.shape(source)[0]\n",
    "        preds = self.model.generate(source, self.target_start_token_idx)\n",
    "        preds = preds.numpy()\n",
    "        for i in range(bs):\n",
    "            target_text = \"\".join([self.idx_to_char[_] for _ in target[i, :]])\n",
    "            prediction = \"\"\n",
    "            for idx in preds[i, :]:\n",
    "                prediction += self.idx_to_char[idx]\n",
    "                if idx == self.target_end_token_idx:\n",
    "                    break\n",
    "            print(f\"target:     {target_text.replace('-','')}\")\n",
    "            print(f\"prediction: {prediction}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6671ac",
   "metadata": {
    "papermill": {
     "duration": 0.048887,
     "end_time": "2023-08-14T07:10:39.791136",
     "exception": false,
     "start_time": "2023-08-14T07:10:39.742249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. **`DisplayOutputs` Callback Class:**\n",
    "   - This is a custom callback class used to display the model's output on a batch of data after every epoch, specifically when the epoch number is a multiple of 5.\n",
    "   - It takes the following arguments during initialization:\n",
    "     - `batch`: A test batch containing the keys \"source\" and \"target\".\n",
    "     - `idx_to_token`: A list containing the vocabulary tokens corresponding to their indices.\n",
    "     - `target_start_token_idx`: Index of the start token in the target vocabulary.\n",
    "     - `target_end_token_idx`: Index of the end token in the target vocabulary.\n",
    "\n",
    "2. **`on_epoch_end` Method:**\n",
    "   - This method is called at the end of each epoch during training.\n",
    "   - It checks if the current epoch number is not divisible by 5 and returns early if so.\n",
    "   - It extracts the source and target data from the provided batch.\n",
    "   - Calls the model's `generate` method to generate predictions for the provided source data, using the provided start token index.\n",
    "   - Iterates over each example in the batch and prints the target text and the generated prediction.\n",
    "   - The target text is obtained by converting the target indices to characters using the `idx_to_char` mapping.\n",
    "   - The prediction is obtained by iterating over the generated indices until the end token index is encountered.\n",
    "\n",
    "This callback is used to display the target text and the model's prediction on a test batch of data after every epoch, but only for epochs with a number that is a multiple of 5. This can help in visually inspecting the model's performance and its ability to generate coherent output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c55846",
   "metadata": {
    "papermill": {
     "duration": 0.046852,
     "end_time": "2023-08-14T07:10:39.890038",
     "exception": false,
     "start_time": "2023-08-14T07:10:39.843186",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7757d1f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:10:39.985642Z",
     "iopub.status.busy": "2023-08-14T07:10:39.985316Z",
     "iopub.status.idle": "2023-08-14T07:10:39.994326Z",
     "shell.execute_reply": "2023-08-14T07:10:39.993341Z"
    },
    "papermill": {
     "duration": 0.059216,
     "end_time": "2023-08-14T07:10:39.996417",
     "exception": false,
     "start_time": "2023-08-14T07:10:39.937201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        init_lr=0.00001,\n",
    "        lr_after_warmup=0.001,\n",
    "        final_lr=0.00001,\n",
    "        warmup_epochs=15,\n",
    "        decay_epochs=85,\n",
    "        steps_per_epoch=203,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.init_lr = init_lr\n",
    "        self.lr_after_warmup = lr_after_warmup\n",
    "        self.final_lr = final_lr\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.decay_epochs = decay_epochs\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "\n",
    "    def calculate_lr(self, epoch):\n",
    "        \"\"\" linear warm up - linear decay \"\"\"\n",
    "        warmup_lr = (\n",
    "            self.init_lr\n",
    "            + ((self.lr_after_warmup - self.init_lr) / (self.warmup_epochs - 1)) * epoch\n",
    "        )\n",
    "        decay_lr = tf.math.maximum(\n",
    "            self.final_lr,\n",
    "            self.lr_after_warmup\n",
    "            - (epoch - self.warmup_epochs)\n",
    "            * (self.lr_after_warmup - self.final_lr)\n",
    "            / self.decay_epochs,\n",
    "        )\n",
    "        return tf.math.minimum(warmup_lr, decay_lr)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        epoch = step // self.steps_per_epoch\n",
    "        return self.calculate_lr(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f8ee15",
   "metadata": {
    "papermill": {
     "duration": 0.046946,
     "end_time": "2023-08-14T07:10:40.090565",
     "exception": false,
     "start_time": "2023-08-14T07:10:40.043619",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. **`CustomSchedule` Class:**\n",
    "   - This is a custom learning rate schedule class that inherits from `keras.optimizers.schedules.LearningRateSchedule`.\n",
    "   - It's designed to define a learning rate schedule with linear warm-up followed by linear decay.\n",
    "\n",
    "2. **Initialization:**\n",
    "   - The constructor `__init__` takes the following arguments:\n",
    "     - `init_lr`: The initial learning rate before warm-up.\n",
    "     - `lr_after_warmup`: The learning rate after the warm-up period.\n",
    "     - `final_lr`: The final learning rate after the decay period.\n",
    "     - `warmup_epochs`: The number of epochs for the warm-up phase.\n",
    "     - `decay_epochs`: The number of epochs for the decay phase.\n",
    "     - `steps_per_epoch`: The number of steps (batches) in one epoch.\n",
    "\n",
    "3. **`calculate_lr` Method:**\n",
    "   - This method calculates the learning rate based on the current epoch number.\n",
    "   - It implements a linear warm-up followed by linear decay.\n",
    "   - For the warm-up phase, it calculates a linear interpolation between `init_lr` and `lr_after_warmup` based on the current epoch.\n",
    "   - For the decay phase, it calculates a linear interpolation between `lr_after_warmup` and `final_lr` based on the current epoch after the warm-up phase.\n",
    "   - The learning rate chosen is the minimum of the warm-up and decay values.\n",
    "\n",
    "4. **`__call__` Method:**\n",
    "   - This method is called when the learning rate is requested at a specific step (usually within an epoch).\n",
    "   - It calculates the current epoch by dividing the step number by `steps_per_epoch`.\n",
    "   - It then calls the `calculate_lr` method to obtain the corresponding learning rate for the current epoch.\n",
    "\n",
    "`CustomSchedule` class defines a learning rate schedule that smoothly increases the learning rate during the warm-up phase and then gradually decreases it during the decay phase. This type of schedule can help stabilize the training process and improve convergence, especially in large-scale models like Transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c49867",
   "metadata": {
    "papermill": {
     "duration": 0.04819,
     "end_time": "2023-08-14T07:10:40.185473",
     "exception": false,
     "start_time": "2023-08-14T07:10:40.137283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create & train the end-to-end model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10b0e238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:10:40.280516Z",
     "iopub.status.busy": "2023-08-14T07:10:40.280203Z",
     "iopub.status.idle": "2023-08-14T07:14:43.263958Z",
     "shell.execute_reply": "2023-08-14T07:14:43.262817Z"
    },
    "papermill": {
     "duration": 243.034344,
     "end_time": "2023-08-14T07:14:43.266879",
     "exception": false,
     "start_time": "2023-08-14T07:10:40.232535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - ETA: 0s - loss: 1.4213target:     <at five#fiftyeight p.m. eastern standard time,>\n",
      "prediction: <the athe the as the the the the the the athe the an an the the an an an the the the the the the athe the the the the are the an anere there the the hed the thed wathe thathond pre as thenthe hang in \n",
      "\n",
      "target:     <at the sound of the second shot>\n",
      "prediction: <the as the an the the an and the the and and the the the an an and the and the and and the the an the the an the thend the the anthe angere the the hed the thed wathere tend anged as thenthe wang ind\n",
      "\n",
      "target:     <a certain number of bedsteads were provided, and there was a slight increase in the ration of bread.>\n",
      "prediction: <the athe the as the the the the the the athe the the the an an the the an an the the the the the the the the the the athe the the on athere the the he there the wathe the on anente hed anthe han t ar\n",
      "\n",
      "target:     <their crimes follow in the lines of others already found, and often more than once, in the calendars.>\n",
      "prediction: <the athe the as the the the the the the athe the the the an an the the an an the the the the the the the the the the athe the the on athere the the he there the wathe the on anente hed anthe han t ar\n",
      "\n",
      "203/203 [==============================] - 243s 1s/step - loss: 1.4213 - val_loss: 1.2983\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(val_ds))\n",
    "\n",
    "# The vocabulary to convert predicted indices into characters\n",
    "idx_to_char = vectorizer.get_vocabulary()\n",
    "display_cb = DisplayOutputs(\n",
    "    batch, idx_to_char, target_start_token_idx=2, target_end_token_idx=3\n",
    ")  # set the arguments as per vocabulary index for '<' and '>'\n",
    "\n",
    "model = Transformer(\n",
    "    num_hid=200,\n",
    "    num_head=2,\n",
    "    num_feed_forward=400,\n",
    "    target_maxlen=max_target_len,\n",
    "    num_layers_enc=4,\n",
    "    num_layers_dec=1,\n",
    "    num_classes=34,\n",
    ")\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True, label_smoothing=0.1,\n",
    ")\n",
    "\n",
    "learning_rate = CustomSchedule(\n",
    "    init_lr=0.00001,\n",
    "    lr_after_warmup=0.001,\n",
    "    final_lr=0.00001,\n",
    "    warmup_epochs=15,\n",
    "    decay_epochs=85,\n",
    "    steps_per_epoch=len(ds)\n",
    ")\n",
    "\n",
    "learning_rate = 0.0001\n",
    "optimizer = keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_fn)\n",
    "\n",
    "history = model.fit(ds, validation_data=val_ds, callbacks=[display_cb], epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3099fc",
   "metadata": {
    "papermill": {
     "duration": 0.062806,
     "end_time": "2023-08-14T07:14:43.400102",
     "exception": false,
     "start_time": "2023-08-14T07:14:43.337296",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. **Data Preparation:**\n",
    "   - `batch = next(iter(val_ds))`: It fetches the next batch from the validation dataset (`val_ds`). This batch will be used for displaying outputs during training.\n",
    "\n",
    "2. **Display Callback Setup:**\n",
    "   - `idx_to_char = vectorizer.get_vocabulary()`: It retrieves the vocabulary of characters from the `VectorizeChar` instance created earlier.\n",
    "   - `display_cb = DisplayOutputs(...)`: An instance of the `DisplayOutputs` callback is created. This callback is used to display predicted and target text outputs after every epoch. It takes the `batch`, `idx_to_char`, `target_start_token_idx`, and `target_end_token_idx` as arguments.\n",
    "\n",
    "3. **Model Initialization:**\n",
    "   - `model = Transformer(...)`: An instance of the `Transformer` model is created. This is a custom Transformer model designed for the specific task.\n",
    "   - Various hyperparameters are passed to configure the model. For example, `num_hid` specifies the hidden dimension size, `num_head` is the number of attention heads, `num_feed_forward` is the feed-forward dimension, and so on.\n",
    "\n",
    "4. **Loss Function Setup:**\n",
    "   - `loss_fn = tf.keras.losses.CategoricalCrossentropy(...)`: A categorical cross-entropy loss function is initialized. This is a common loss function used for multi-class classification tasks. The argument `from_logits=True` indicates that the model's output logits are used (before applying softmax).\n",
    "\n",
    "5. **Learning Rate Schedule Setup:**\n",
    "   - `learning_rate = CustomSchedule(...)`: An instance of the `CustomSchedule` learning rate schedule is created. This custom schedule defines how the learning rate will change during training based on the specified parameters.\n",
    "   - Alternatively, `learning_rate = 0.0001` is assigned a fixed learning rate value.\n",
    "\n",
    "6. **Optimizer Setup:**\n",
    "   - `optimizer = keras.optimizers.Adam(...)`: An Adam optimizer instance is created, and the previously defined `learning_rate` (either from the custom schedule or the fixed value) is passed to it.\n",
    "\n",
    "7. **Model Compilation:**\n",
    "   - `model.compile(...)`: The model is compiled with the specified optimizer and loss function. This prepares the model for training.\n",
    "\n",
    "8. **Training Loop:**\n",
    "   - `history = model.fit(...)`: The training loop is executed using the `fit` method. The training data (`ds`) and validation data (`val_ds`) are provided. The `callbacks` parameter includes the `display_cb`, which will display outputs after each epoch.\n",
    "   - The training is performed for a single epoch (`epochs=1`), which means the model will go through the entire training dataset once.\n",
    "\n",
    "Overall, the code sets up a Transformer-based model, defines the necessary components (loss function, optimizer, learning rate schedule), and trains the model for one epoch while displaying predicted and target text outputs at specific intervals during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c6ba3e",
   "metadata": {
    "papermill": {
     "duration": 0.065463,
     "end_time": "2023-08-14T07:14:43.528800",
     "exception": false,
     "start_time": "2023-08-14T07:14:43.463337",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Inspiration:** [Automatic Speech Recognition with Transformer](https://keras.io/examples/audio/transformer_asr/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 667.188646,
   "end_time": "2023-08-14T07:14:46.683236",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-14T07:03:39.494590",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
