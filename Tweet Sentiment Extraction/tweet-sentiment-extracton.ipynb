{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Load Libraries, Data, Tokenizer\nWe will use HuggingFace transformers [here][1]\n\n[1]: https://huggingface.co/transformers/","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom sklearn.model_selection import StratifiedKFold\nimport transformers\nfrom transformers import RobertaConfig\nfrom transformers import TFRobertaModel\nimport tokenizers\nprint('TF version',tf.__version__)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-11-08T17:27:54.867747Z","iopub.execute_input":"2022-11-08T17:27:54.868364Z","iopub.status.idle":"2022-11-08T17:28:02.110959Z","shell.execute_reply.started":"2022-11-08T17:27:54.868307Z","shell.execute_reply":"2022-11-08T17:28:02.109929Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2022-11-08 17:27:57.653209: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-08 17:27:57.654202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-08 17:27:57.655291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-08 17:27:57.656048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-08 17:27:57.656789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-08 17:27:57.657559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from S","output_type":"stream"},{"name":"stdout","text":"TF version 2.6.4\n/kaggle/input/tf-roberta/pretrained-roberta-base.h5\n/kaggle/input/tf-roberta/config-roberta-base.json\n/kaggle/input/tf-roberta/vocab-roberta-base.json\n/kaggle/input/tf-roberta/merges-roberta-base.txt\n/kaggle/input/tweet-sentiment-extraction/sample_submission.csv\n/kaggle/input/tweet-sentiment-extraction/train.csv\n/kaggle/input/tweet-sentiment-extraction/test.csv\n/kaggle/input/tweet-sentiment-extracton/v0-roberta-2.h5\n/kaggle/input/tweet-sentiment-extracton/v0-roberta-3.h5\n/kaggle/input/tweet-sentiment-extracton/v0-roberta-1.h5\n/kaggle/input/tweet-sentiment-extracton/v0-roberta-4.h5\n/kaggle/input/tweet-sentiment-extracton/__results__.html\n/kaggle/input/tweet-sentiment-extracton/submission.csv\n/kaggle/input/tweet-sentiment-extracton/__notebook__.ipynb\n/kaggle/input/tweet-sentiment-extracton/v0-roberta-0.h5\n/kaggle/input/tweet-sentiment-extracton/__output__.json\n/kaggle/input/tweet-sentiment-extracton/custom.css\n","output_type":"stream"},{"name":"stderr","text":"ysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-08 17:27:57.659140: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-08 17:27:57.884370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-08 17:27:57.885245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-08 17:27:57.886044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-08 17:27:57.886821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-08 17:27:57.887635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-08 17:27:57.888412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-08 17:28:01.774760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-08 17:28:01.775685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-08 17:28:01.776407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-08 17:28:01.777124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-08 17:28:01.777873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-08 17:28:01.778606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13351 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2022-11-08 17:28:01.779041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-08 17:28:01.779742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13351 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}]},{"cell_type":"code","source":"MAX_LEN = 96\nPATH = '../input/tf-roberta/'\ntokenizer = tokenizers.ByteLevelBPETokenizer(\n    vocab=PATH+'vocab-roberta-base.json', \n    merges=PATH+'merges-roberta-base.txt', \n    lowercase=True,\n    add_prefix_space=True\n)\n\nsentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}\ntrain = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv').fillna('')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-08T17:28:02.118557Z","iopub.execute_input":"2022-11-08T17:28:02.119203Z","iopub.status.idle":"2022-11-08T17:28:02.281425Z","shell.execute_reply.started":"2022-11-08T17:28:02.119166Z","shell.execute_reply":"2022-11-08T17:28:02.280450Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"       textID                                               text  \\\n0  cb774db0d1                I`d have responded, if I were going   \n1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n2  088c60f138                          my boss is bullying me...   \n3  9642c003ef                     what interview! leave me alone   \n4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n\n                         selected_text sentiment  \n0  I`d have responded, if I were going   neutral  \n1                             Sooo SAD  negative  \n2                          bullying me  negative  \n3                       leave me alone  negative  \n4                        Sons of ****,  negative  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>358bd9e861</td>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>Sons of ****,</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Shape :\",train.shape)\nprint(\"Data_Types : \\n\",train.dtypes)","metadata":{"execution":{"iopub.status.busy":"2022-11-08T17:28:02.283178Z","iopub.execute_input":"2022-11-08T17:28:02.283607Z","iopub.status.idle":"2022-11-08T17:28:02.289878Z","shell.execute_reply.started":"2022-11-08T17:28:02.283565Z","shell.execute_reply":"2022-11-08T17:28:02.288890Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Shape : (27481, 4)\nData_Types : \n textID           object\ntext             object\nselected_text    object\nsentiment        object\ndtype: object\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training Data\nWe will now convert the training data into arrays that roBERTa understands. Here are example inputs and targets:\n\nThe tokenization logic below is inspired by Abhishek's PyTorch notebook [here][1].\n\n[1]: https://www.kaggle.com/abhishek/roberta-inference-5-folds","metadata":{}},{"cell_type":"code","source":"ct = train.shape[0]\ninput_ids = np.ones((ct,MAX_LEN),dtype='int32')\nattention_mask = np.zeros((ct,MAX_LEN),dtype='int32')\ntoken_type_ids = np.zeros((ct,MAX_LEN),dtype='int32')\nstart_tokens = np.zeros((ct,MAX_LEN),dtype='int32')\nend_tokens = np.zeros((ct,MAX_LEN),dtype='int32')\n\nfor k in range(train.shape[0]):\n    \n    # FIND OVERLAP\n    text1 = \" \"+\" \".join(train.loc[k,'text'].split())\n    text2 = \" \".join(train.loc[k,'selected_text'].split())\n    idx = text1.find(text2)\n    chars = np.zeros((len(text1)))\n    chars[idx:idx+len(text2)]=1\n    if text1[idx-1]==' ': chars[idx-1] = 1 \n    enc = tokenizer.encode(text1) \n        \n    # ID_OFFSETS\n    offsets = []; idx=0\n    for t in enc.ids:\n        w = tokenizer.decode([t])\n        offsets.append((idx,idx+len(w)))\n        idx += len(w)\n    \n    # START END TOKENS\n    toks = []\n    for i,(a,b) in enumerate(offsets):\n        sm = np.sum(chars[a:b])\n        if sm>0: toks.append(i) \n        \n    s_tok = sentiment_id[train.loc[k,'sentiment']]\n    input_ids[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n    attention_mask[k,:len(enc.ids)+5] = 1\n    if len(toks)>0:\n        start_tokens[k,toks[0]+1] = 1\n        end_tokens[k,toks[-1]+1] = 1","metadata":{"execution":{"iopub.status.busy":"2022-11-08T17:28:02.293396Z","iopub.execute_input":"2022-11-08T17:28:02.294098Z","iopub.status.idle":"2022-11-08T17:28:09.539014Z","shell.execute_reply.started":"2022-11-08T17:28:02.294030Z","shell.execute_reply":"2022-11-08T17:28:09.537722Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Test Data\nWe must tokenize the test data exactly the same as we tokenize the training data","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv').fillna('')\n\nct = test.shape[0]\ninput_ids_t = np.ones((ct,MAX_LEN),dtype='int32')\nattention_mask_t = np.zeros((ct,MAX_LEN),dtype='int32')\ntoken_type_ids_t = np.zeros((ct,MAX_LEN),dtype='int32')\n\nfor k in range(test.shape[0]):\n        \n    # INPUT_IDS\n    text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n    enc = tokenizer.encode(text1)                \n    s_tok = sentiment_id[test.loc[k,'sentiment']]\n    input_ids_t[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n    attention_mask_t[k,:len(enc.ids)+5] = 1","metadata":{"execution":{"iopub.status.busy":"2022-11-08T17:28:09.540573Z","iopub.execute_input":"2022-11-08T17:28:09.541329Z","iopub.status.idle":"2022-11-08T17:28:09.852171Z","shell.execute_reply.started":"2022-11-08T17:28:09.541243Z","shell.execute_reply":"2022-11-08T17:28:09.851196Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Training Data\nWe will now convert the training data into arrays that roBERTa understands. Here are example inputs and targets:\n\nThe tokenization logic below is inspired by Abhishek's PyTorch notebook here.","metadata":{}},{"cell_type":"code","source":"def build_model():\n    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n    tok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n\n    config = RobertaConfig.from_pretrained(PATH+'config-roberta-base.json')\n    bert_model = TFRobertaModel.from_pretrained(PATH+'pretrained-roberta-base.h5',config=config)\n    x = bert_model(ids,attention_mask=att,token_type_ids=tok)\n    \n    x1 = tf.keras.layers.Dropout(0.1)(x[0]) \n    x1 = tf.keras.layers.Conv1D(1,1)(x1)\n    x1 = tf.keras.layers.Flatten()(x1)\n    x1 = tf.keras.layers.Activation('softmax')(x1)\n    \n    x2 = tf.keras.layers.Dropout(0.1)(x[0]) \n    x2 = tf.keras.layers.Conv1D(1,1)(x2)\n    x2 = tf.keras.layers.Flatten()(x2)\n    x2 = tf.keras.layers.Activation('softmax')(x2)\n\n    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-11-08T17:28:09.853738Z","iopub.execute_input":"2022-11-08T17:28:09.854149Z","iopub.status.idle":"2022-11-08T17:28:09.864133Z","shell.execute_reply.started":"2022-11-08T17:28:09.854111Z","shell.execute_reply":"2022-11-08T17:28:09.862828Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Metric\nCalculate the scores for submission.","metadata":{}},{"cell_type":"code","source":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    if (len(a)==0) & (len(b)==0): return 0.5\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","metadata":{"execution":{"iopub.status.busy":"2022-11-08T17:28:09.865865Z","iopub.execute_input":"2022-11-08T17:28:09.866328Z","iopub.status.idle":"2022-11-08T17:28:09.874762Z","shell.execute_reply.started":"2022-11-08T17:28:09.866292Z","shell.execute_reply":"2022-11-08T17:28:09.873806Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Train roBERTa Model\nWe train with 5 Stratified KFolds (based on sentiment stratification). Each fold, the best model weights are saved and then reloaded before oof prediction and test prediction. Therefore you can run this code offline and upload your 5 fold models to a private Kaggle dataset. Then run this notebook and comment out the line `model.fit()`. Instead your notebook will load your model weights from offline training in the line `model.load_weights()`. Update this to have the correct path. Also make sure you change the KFold seed below to match your offline training. Then this notebook will proceed to use your offline models to predict oof and predict test.","metadata":{}},{"cell_type":"markdown","source":"## Load the pretrained model","metadata":{}},{"cell_type":"code","source":"jac = []; VER='v0'; DISPLAY=1 # USE display=1 FOR INTERACTIVE\n\noof_start = np.zeros((input_ids.shape[0],MAX_LEN))\n\noof_end = np.zeros((input_ids.shape[0],MAX_LEN))\n\npreds_start = np.zeros((input_ids_t.shape[0],MAX_LEN))\n\npreds_end = np.zeros((input_ids_t.shape[0],MAX_LEN))\n\nskf = StratifiedKFold(n_splits=5,shuffle=True,random_state=7)\n\npath = '/kaggle/input/tweet-sentiment-extracton/'\n\nfor fold,(idxT,idxV) in enumerate(skf.split(input_ids,train.sentiment.values)):\n\n    print('#'*25)\n    print('### FOLD %i'%(fold+1))\n    print('#'*25)\n    \n    K.clear_session()\n    model = build_model()\n        \n    sv = tf.keras.callbacks.ModelCheckpoint(\n        '%s-roberta-%i.h5'%(VER,fold), monitor='val_loss', verbose=1, save_best_only=True,\n        save_weights_only=True, mode='auto', save_freq='epoch')\n        \n    '''\n    model.fit([input_ids[idxT,], attention_mask[idxT,], token_type_ids[idxT,]], [start_tokens[idxT,], end_tokens[idxT,]], \n        epochs=3, batch_size=32, verbose=DISPLAY, callbacks=[sv],\n        validation_data=([input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]], \n        [start_tokens[idxV,], end_tokens[idxV,]]))\n    '''\n    print('Loading model...')\n    model.load_weights(path +'%s-roberta-%i.h5'%(VER,fold))\n    \n    print('Predicting OOF...')\n    oof_start[idxV,],oof_end[idxV,] = model.predict([input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]],verbose=DISPLAY)\n    \n    print('Predicting Test...')\n    preds = model.predict([input_ids_t,attention_mask_t,token_type_ids_t],verbose=DISPLAY)\n    preds_start += preds[0]/skf.n_splits\n    preds_end += preds[1]/skf.n_splits\n    \n    # DISPLAY FOLD JACCARD\n    all = []\n    for k in idxV:\n        a = np.argmax(oof_start[k,])\n        b = np.argmax(oof_end[k,])\n        if a>b: \n            st = train.loc[k,'text'] # IMPROVE CV/LB with better choice here\n        else:\n            text1 = \" \"+\" \".join(train.loc[k,'text'].split())\n            enc = tokenizer.encode(text1)\n            st = tokenizer.decode(enc.ids[a-1:b])\n        all.append(jaccard(st,train.loc[k,'selected_text']))\n    jac.append(np.mean(all))\n    print('>>>> FOLD %i Jaccard ='%(fold+1),np.mean(all))\n    print()","metadata":{"execution":{"iopub.status.busy":"2022-11-08T17:28:09.876402Z","iopub.execute_input":"2022-11-08T17:28:09.876847Z","iopub.status.idle":"2022-11-08T17:36:11.731016Z","shell.execute_reply.started":"2022-11-08T17:28:09.876813Z","shell.execute_reply":"2022-11-08T17:36:11.729876Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"#########################\n### FOLD 1\n#########################\n","output_type":"stream"},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFRobertaModel.\n\nAll the layers of TFRobertaModel were initialized from the model checkpoint at ../input/tf-roberta/pretrained-roberta-base.h5.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Loading model...\nPredicting OOF...\n","output_type":"stream"},{"name":"stderr","text":"2022-11-08 17:28:27.772288: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n2022-11-08 17:28:31.074832: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"172/172 [==============================] - 41s 216ms/step\nPredicting Test...\n111/111 [==============================] - 24s 214ms/step\n>>>> FOLD 1 Jaccard = 0.7368520640204638\n\n#########################\n### FOLD 2\n#########################\n","output_type":"stream"},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFRobertaModel.\n\nAll the layers of TFRobertaModel were initialized from the model checkpoint at ../input/tf-roberta/pretrained-roberta-base.h5.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Loading model...\nPredicting OOF...\n172/172 [==============================] - 40s 215ms/step\nPredicting Test...\n111/111 [==============================] - 24s 215ms/step\n>>>> FOLD 2 Jaccard = 0.7574581160933693\n\n#########################\n### FOLD 3\n#########################\n","output_type":"stream"},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFRobertaModel.\n\nAll the layers of TFRobertaModel were initialized from the model checkpoint at ../input/tf-roberta/pretrained-roberta-base.h5.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Loading model...\nPredicting OOF...\n172/172 [==============================] - 39s 214ms/step\nPredicting Test...\n111/111 [==============================] - 24s 216ms/step\n>>>> FOLD 3 Jaccard = 0.7363162272696699\n\n#########################\n### FOLD 4\n#########################\n","output_type":"stream"},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFRobertaModel.\n\nAll the layers of TFRobertaModel were initialized from the model checkpoint at ../input/tf-roberta/pretrained-roberta-base.h5.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Loading model...\nPredicting OOF...\n172/172 [==============================] - 40s 214ms/step\nPredicting Test...\n111/111 [==============================] - 24s 216ms/step\n>>>> FOLD 4 Jaccard = 0.7444315995198243\n\n#########################\n### FOLD 5\n#########################\n","output_type":"stream"},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFRobertaModel.\n\nAll the layers of TFRobertaModel were initialized from the model checkpoint at ../input/tf-roberta/pretrained-roberta-base.h5.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Loading model...\nPredicting OOF...\n172/172 [==============================] - 39s 214ms/step\nPredicting Test...\n111/111 [==============================] - 24s 215ms/step\n>>>> FOLD 5 Jaccard = 0.750765288079518\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-08T17:36:11.735781Z","iopub.execute_input":"2022-11-08T17:36:11.738523Z","iopub.status.idle":"2022-11-08T17:36:11.758875Z","shell.execute_reply.started":"2022-11-08T17:36:11.738465Z","shell.execute_reply":"2022-11-08T17:36:11.757680Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 96)]         0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            [(None, 96)]         0                                            \n__________________________________________________________________________________________________\ninput_3 (InputLayer)            [(None, 96)]         0                                            \n__________________________________________________________________________________________________\ntf_roberta_model (TFRobertaMode TFBaseModelOutputWit 124645632   input_1[0][0]                    \n                                                                 input_2[0][0]                    \n                                                                 input_3[0][0]                    \n__________________________________________________________________________________________________\ndropout_37 (Dropout)            (None, 96, 768)      0           tf_roberta_model[0][0]           \n__________________________________________________________________________________________________\ndropout_38 (Dropout)            (None, 96, 768)      0           tf_roberta_model[0][0]           \n__________________________________________________________________________________________________\nconv1d (Conv1D)                 (None, 96, 1)        769         dropout_37[0][0]                 \n__________________________________________________________________________________________________\nconv1d_1 (Conv1D)               (None, 96, 1)        769         dropout_38[0][0]                 \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 96)           0           conv1d[0][0]                     \n__________________________________________________________________________________________________\nflatten_1 (Flatten)             (None, 96)           0           conv1d_1[0][0]                   \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 96)           0           flatten[0][0]                    \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 96)           0           flatten_1[0][0]                  \n==================================================================================================\nTotal params: 124,647,170\nTrainable params: 124,647,170\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"print('>>>> OVERALL 5Fold CV Jaccard =',np.mean(jac))","metadata":{"execution":{"iopub.status.busy":"2022-11-08T17:36:52.776204Z","iopub.execute_input":"2022-11-08T17:36:52.776667Z","iopub.status.idle":"2022-11-08T17:36:52.783411Z","shell.execute_reply.started":"2022-11-08T17:36:52.776630Z","shell.execute_reply":"2022-11-08T17:36:52.782373Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":">>>> OVERALL 5Fold CV Jaccard = 0.745164658996569\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Kaggle Submission","metadata":{}},{"cell_type":"code","source":"all = []\nfor k in range(input_ids_t.shape[0]):\n    a = np.argmax(preds_start[k,])\n    b = np.argmax(preds_end[k,])\n    if a>b: \n        st = test.loc[k,'text']\n    else:\n        text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n        enc = tokenizer.encode(text1)\n        st = tokenizer.decode(enc.ids[a-1:b])\n    all.append(st)","metadata":{"execution":{"iopub.status.busy":"2022-11-08T17:36:52.787204Z","iopub.execute_input":"2022-11-08T17:36:52.788339Z","iopub.status.idle":"2022-11-08T17:36:53.110197Z","shell.execute_reply.started":"2022-11-08T17:36:52.788301Z","shell.execute_reply":"2022-11-08T17:36:53.109207Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"test['selected_text'] = all\ntest[['textID','selected_text']].to_csv('submission.csv',index=False)\npd.set_option('max_colwidth', 60)\ntest.sample(10)","metadata":{"execution":{"iopub.status.busy":"2022-11-08T17:54:23.197383Z","iopub.execute_input":"2022-11-08T17:54:23.197938Z","iopub.status.idle":"2022-11-08T17:54:23.235840Z","shell.execute_reply.started":"2022-11-08T17:54:23.197902Z","shell.execute_reply":"2022-11-08T17:54:23.234833Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"          textID                                                         text  \\\n1656  10b36df3e0                             That didn`t work, unfortunately.   \n3308  ae45bdeb6d                  Humidity is NOT my friend! Just ask my hair   \n2432  75b9768faf  Today felt so much more crazy than it was!!  I digg the ...   \n3312  cbd87d2326                        http://twitpic.com/5ut6j - Poor Thing   \n3045  f19f0c1482            i need to go out of office again.. i am melting..   \n111   3112944847                                   ughh on the phone with HP!   \n665   0237b6fd87                                           good morning world   \n3260  95305a8336                                                  im surfin..   \n229   d25c4179f6  sorry for my lack of tweets  ive been buzy. new vid this...   \n1671  6dc625db0d  my newsreader is filling up with blogs  yay! keep pm`ing...   \n\n     sentiment                                       selected_text  \n1656  negative                                      unfortunately.  \n3308  negative                          humidity is not my friend!  \n2432  positive                                   there pretty cool  \n3312  negative                                          poor thing  \n3045   neutral   i need to go out of office again.. i am melting..  \n111    neutral                          ughh on the phone with hp!  \n665   positive                                  good morning world  \n3260   neutral                                         im surfin..  \n229   negative                                               sorry  \n1671  positive                                i love reading them!  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>sentiment</th>\n      <th>selected_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1656</th>\n      <td>10b36df3e0</td>\n      <td>That didn`t work, unfortunately.</td>\n      <td>negative</td>\n      <td>unfortunately.</td>\n    </tr>\n    <tr>\n      <th>3308</th>\n      <td>ae45bdeb6d</td>\n      <td>Humidity is NOT my friend! Just ask my hair</td>\n      <td>negative</td>\n      <td>humidity is not my friend!</td>\n    </tr>\n    <tr>\n      <th>2432</th>\n      <td>75b9768faf</td>\n      <td>Today felt so much more crazy than it was!!  I digg the ...</td>\n      <td>positive</td>\n      <td>there pretty cool</td>\n    </tr>\n    <tr>\n      <th>3312</th>\n      <td>cbd87d2326</td>\n      <td>http://twitpic.com/5ut6j - Poor Thing</td>\n      <td>negative</td>\n      <td>poor thing</td>\n    </tr>\n    <tr>\n      <th>3045</th>\n      <td>f19f0c1482</td>\n      <td>i need to go out of office again.. i am melting..</td>\n      <td>neutral</td>\n      <td>i need to go out of office again.. i am melting..</td>\n    </tr>\n    <tr>\n      <th>111</th>\n      <td>3112944847</td>\n      <td>ughh on the phone with HP!</td>\n      <td>neutral</td>\n      <td>ughh on the phone with hp!</td>\n    </tr>\n    <tr>\n      <th>665</th>\n      <td>0237b6fd87</td>\n      <td>good morning world</td>\n      <td>positive</td>\n      <td>good morning world</td>\n    </tr>\n    <tr>\n      <th>3260</th>\n      <td>95305a8336</td>\n      <td>im surfin..</td>\n      <td>neutral</td>\n      <td>im surfin..</td>\n    </tr>\n    <tr>\n      <th>229</th>\n      <td>d25c4179f6</td>\n      <td>sorry for my lack of tweets  ive been buzy. new vid this...</td>\n      <td>negative</td>\n      <td>sorry</td>\n    </tr>\n    <tr>\n      <th>1671</th>\n      <td>6dc625db0d</td>\n      <td>my newsreader is filling up with blogs  yay! keep pm`ing...</td>\n      <td>positive</td>\n      <td>i love reading them!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}