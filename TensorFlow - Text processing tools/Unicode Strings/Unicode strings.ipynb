{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75fb563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14e8d4e",
   "metadata": {},
   "source": [
    "### The tf.string data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "817d50ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe0\\xa5\\x90 \\xe0\\xa4\\x97\\xe0\\xa4\\x82 \\xe0\\xa4\\x97\\xe0\\xa4\\xa3\\xe0\\xa4\\xaa\\xe0\\xa4\\xa4\\xe0\\xa4\\xaf\\xe0\\xa5\\x87 \\xe0\\xa4\\xa8\\xe0\\xa4\\xae:'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(u\"‡•ê ‡§ó‡§Ç ‡§ó‡§£‡§™‡§§‡§Ø‡•á ‡§®‡§Æ:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13449af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡•ê ‡§ó‡§Ç ‡§ó‡§£‡§™‡§§‡§Ø‡•á ‡§®‡§Æ:'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#s = '''\\xe0\\xa5\\x90 \\xe0\\xa4\\x97\\xe0\\xa4\\x82 \\xe0\\xa4\\x97\\xe0\\xa4\\xa3\\xe0\\xa4\\xaa\\xe0\\xa4\\xa4\\xe0\\xa4\\xaf\\xe0\\xa5\\x87 \\xe0\\xa4\\xa8\\xe0\\xa4\\xae:'''\n",
    "#s.encode('raw-unicode-escape').decode('utf8')\n",
    "tf.constant(u\"‡•ê ‡§ó‡§Ç ‡§ó‡§£‡§™‡§§‡§Ø‡•á ‡§®‡§Æ:\").numpy().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14991da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'Thanks \\xf0\\x9f\\x98\\x8a'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(u\"Thanks üòä\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c175735f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b\"You're\", b'welcome!'], dtype=object)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([u\"You're\", u\"welcome!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7b48f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([u\"You're\", u\"welcome!\"]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a1c89d",
   "metadata": {},
   "source": [
    "## Representing Unicode\n",
    "\n",
    "There are two standard ways to represent a Unicode string in TensorFlow:\n",
    "- string scalar ‚Äî where the sequence of code points is encoded using a known character encoding.\n",
    "- int32 vector ‚Äî where each position contains a single code point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0b9759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\xa4\\x84\\xe7\\x90\\x86'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode string, represented as a UTF-8 encoded string scalar.\n",
    "text_utf8 = tf.constant(u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\")\n",
    "text_utf8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97f09741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ËØ≠Ë®ÄÂ§ÑÁêÜ'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_utf8.numpy().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cdec82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\x8b\\xed\\x8a\\x00Y\\x04t\\x06'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode string, represented as a UTF-16-BE encoded string scalar.\n",
    "text_utf16be = tf.constant(u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\".encode(\"UTF-16-BE\"))\n",
    "text_utf16be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61fddd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([35821, 35328, 22788, 29702])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode string, represented as a vector of Unicode code points.\n",
    "text_chars = tf.constant([ord(char) for char in u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\"])\n",
    "text_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750af299",
   "metadata": {},
   "source": [
    "### With Hindi & Sanskrit text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30f0335d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTF-8 encoded >> tf.Tensor(b'\\xe0\\xa5\\x90', shape=(), dtype=string)\n",
      "Decode UTF-8 encoded value >> ‡•ê\n",
      "UTF-16BE encoded >> tf.Tensor(b'\\tP', shape=(), dtype=string)\n",
      "Decode UTF-16BE encoded value >> ‡•ê\n",
      "Unicode code points >> tf.Tensor([2384], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Unicode string, represented as a UTF-8 encoded string scalar.\n",
    "text_utf8 = tf.constant(u\"‡•ê\")\n",
    "print('UTF-8 encoded >>',text_utf8)\n",
    "\n",
    "# Decode UTF-8 encoded string\n",
    "print('Decode UTF-8 encoded value >>', text_utf8.numpy().decode())\n",
    "\n",
    "# Unicode string, represented as a UTF-16-BE encoded string scalar.\n",
    "text_utf16be = tf.constant(u\"‡•ê\".encode(\"UTF-16-BE\"))\n",
    "print('UTF-16BE encoded >>',text_utf16be)\n",
    "\n",
    "# Decode UTF-8 encoded string\n",
    "print('Decode UTF-16BE encoded value >>', text_utf16be.numpy().decode('UTF-16-BE'))\n",
    "\n",
    "# Unicode string, represented as a vector of Unicode code points.\n",
    "text_chars = tf.constant([ord(char) for char in u\"‡•ê\"])\n",
    "print('Unicode code points >>',text_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fe0acf",
   "metadata": {},
   "source": [
    "### Converting between representations\n",
    "TensorFlow provides operations to convert between these different representations:\n",
    "- `tf.strings.unicode_decode`: Converts an encoded string scalar to a vector of code points.\n",
    "- `tf.strings.unicode_encode`: Converts a vector of code points to an encoded string scalar.\n",
    "- `tf.strings.unicode_transcode`: Converts an encoded string scalar to a different encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b435ab3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([2384])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converts an encoded string scalar to a vector of code points.\n",
    "text_utf8 = tf.constant(u\"‡•ê\")\n",
    "\n",
    "tf.strings.unicode_decode(text_utf8, \n",
    "                          input_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35ed2c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe0\\xa5\\x90'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converts a vector of code points to an encoded string scalar.\n",
    "text_chars = tf.constant([ord(char) for char in u\"‡•ê\"])\n",
    "\n",
    "tf.strings.unicode_encode(text_chars, \n",
    "                          output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f424f3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\tP'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Converts an encoded string scalar to a different encoding.\n",
    "tf.strings.unicode_transcode(text_utf8,\n",
    "                             input_encoding='UTF8',\n",
    "                             output_encoding='UTF-16-BE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd413b58",
   "metadata": {},
   "source": [
    "### Batch dimensions\n",
    "When decoding multiple strings, the number of characters in each string may not be equal. The return result is a `tf.RaggedTensor`, where the innermost dimension length varies depending on the number of characters in each string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76cbe149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[104, 195, 108, 108, 111]\n",
      "[87, 104, 97, 116, 32, 105, 115, 32, 116, 104, 101, 32, 119, 101, 97, 116, 104, 101, 114, 32, 116, 111, 109, 111, 114, 114, 111, 119]\n",
      "[71, 246, 246, 100, 110, 105, 103, 104, 116]\n",
      "[128522]\n"
     ]
    }
   ],
   "source": [
    "# A batch of Unicode strings, each represented as a UTF8-encoded string.\n",
    "batch_utf8 = [s.encode('UTF-8') for s in\n",
    "              [u'h√Éllo', u'What is the weather tomorrow', u'G√∂√∂dnight', u'üòä']]\n",
    "batch_chars_ragged = tf.strings.unicode_decode(batch_utf8,\n",
    "                                               input_encoding='UTF-8')\n",
    "for sentence_chars in batch_chars_ragged.to_list():\n",
    "    print(sentence_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0807c8",
   "metadata": {},
   "source": [
    " Use this `tf.RaggedTensor` directly, or convert it to a dense `tf.Tensor` with padding or a `tf.sparse.SparseTensor` using the methods `tf.RaggedTensor.to_tensor` and `tf.RaggedTensor.to_sparse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2bb4da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   104    195    108    108    111     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]\n",
      " [    87    104     97    116     32    105    115     32    116    104\n",
      "     101     32    119    101     97    116    104    101    114     32\n",
      "     116    111    109    111    114    114    111    119]\n",
      " [    71    246    246    100    110    105    103    104    116     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]\n",
      " [128522     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]]\n"
     ]
    }
   ],
   "source": [
    "batch_chars_padded = batch_chars_ragged.to_tensor(default_value=-1)\n",
    "print(batch_chars_padded.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb6a4d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   104,    195,    108,    108,    111,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _]\n",
      " [    87,    104,     97,    116,     32,    105,    115,     32,    116,    104,    101,     32,    119,    101,     97,    116,    104,    101,    114,     32,    116,    111,    109,    111,    114,    114,    111,    119]\n",
      " [    71,    246,    246,    100,    110,    105,    103,    104,    116,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _]\n",
      " [128522,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _]]\n"
     ]
    }
   ],
   "source": [
    "batch_chars_sparse = batch_chars_ragged.to_sparse()\n",
    "\n",
    "nrows, ncols = batch_chars_sparse.dense_shape.numpy()\n",
    "elements = [['_' for i in range(ncols)] for j in range(nrows)]\n",
    "for (row, col), value in zip(batch_chars_sparse.indices.numpy(), batch_chars_sparse.values.numpy()):\n",
    "    elements[row][col] = str(value)\n",
    "# max_width = max(len(value) for row in elements for value in row)\n",
    "value_lengths = []\n",
    "for row in elements:\n",
    "    for value in row:\n",
    "        value_lengths.append(len(value))\n",
    "max_width = max(value_lengths)\n",
    "\n",
    "print('[%s]' % '\\n '.join(\n",
    "    '[%s]' % ', '.join(value.rjust(max_width) for value in row)\n",
    "    for row in elements))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61bacaf",
   "metadata": {},
   "source": [
    "When encoding multiple strings with the same lengths, use a `tf.Tensor` as the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58dcd5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'cat', b'dog', b'cow'], dtype=object)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode([[99, 97, 116], [100, 111, 103], [99, 111, 119]], output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f72c7fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(batch_chars_ragged, output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc84c7db",
   "metadata": {},
   "source": [
    "If you have a tensor with multiple strings in padded or sparse format, convert it first into a `tf.RaggedTensor` before calling tf.strings.unicode_encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42038710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(\n",
    "    tf.RaggedTensor.from_sparse(batch_chars_sparse),\n",
    "    output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b0dcca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor = tf.strings.unicode_encode(\n",
    "    tf.RaggedTensor.from_tensor(batch_chars_padded, padding=-1),\n",
    "    output_encoding='UTF-8')\n",
    "Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36dfdaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'h\\xc3\\x83llo'  |  h√Éllo\n",
      "b'What is the weather tomorrow'  |  What is the weather tomorrow\n",
      "b'G\\xc3\\xb6\\xc3\\xb6dnight'  |  G√∂√∂dnight\n",
      "b'\\xf0\\x9f\\x98\\x8a'  |  üòä\n"
     ]
    }
   ],
   "source": [
    "for byt in Tensor.numpy():\n",
    "    print(byt,' | ',byt.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceea3863",
   "metadata": {},
   "source": [
    "## Unicode operations\n",
    "### Character length\n",
    "Use the unit parameter of the `tf.strings.length` op to indicate how character lengths should be computed. `unit` defaults to `\"BYTE\"`, but it can be set to other values, such as `\"UTF8_CHAR\"` or `\"UTF16_CHAR\"`, to determine the number of Unicode codepoints in each encoded string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55b25452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 bytes; 18 UTF-8 characters\n"
     ]
    }
   ],
   "source": [
    "# Note that the final character takes up 4 bytes in UTF8.\n",
    "thanks = u'Thanks üòä'.encode('UTF-16BE')\n",
    "num_bytes = tf.strings.length(thanks).numpy()\n",
    "num_chars = tf.strings.length(thanks, unit='UTF8_CHAR').numpy()\n",
    "print('{} bytes; {} UTF-8 characters'.format(num_bytes, num_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be6f831c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 bytes; 8 UTF-8 characters\n"
     ]
    }
   ],
   "source": [
    "# Note that the final character takes up 4 bytes in UTF8.\n",
    "thanks = u'Thanks üòä'.encode('UTF-8')\n",
    "num_bytes = tf.strings.length(thanks).numpy()\n",
    "num_chars = tf.strings.length(thanks, unit='UTF8_CHAR').numpy()\n",
    "print('{} bytes; {} UTF-8 characters'.format(num_bytes, num_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a19deba",
   "metadata": {},
   "source": [
    "### Character substrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "451ac8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Thanks \\xf0\\x9f\\x98\\x8a'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For each string in the input `Tensor`, creates a substring starting at index `pos` with a total length of `len`.\n",
    "tf.strings.substr(thanks, pos=0, len=len(thanks)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a06bbf15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thanks üòä'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.substr(thanks, pos=0, len=len(thanks)).numpy().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9deabba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xf0\\x9f\\x98\\x8a'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, unit='BYTE' (default). Returns a single byte with len=1\n",
    "tf.strings.substr(thanks, pos=7, len=4).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ec71f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'üòä'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.substr(thanks, pos=7, len=4).numpy().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cecb76af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xf0'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, unit='BYTE' (default). Returns a single byte with len=1\n",
    "tf.strings.substr(thanks, pos=7, len=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1593d365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xf0\\x9f\\x98\\x8a'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specifying unit='UTF8_CHAR', returns a single 4 byte character in this case\n",
    "tf.strings.substr(thanks, pos=7, len=1, unit='UTF8_CHAR').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36dfb45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'üòä'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.substr(thanks, pos=7, len=1, unit='UTF8_CHAR').numpy().decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4ebd66",
   "metadata": {},
   "source": [
    "### Split Unicode strings\n",
    "The `tf.strings.unicode_split` operation splits unicode strings into substrings of individual characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c8459b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'T', b'h', b'a', b'n', b'k', b's', b' ', b'\\xf0\\x9f\\x98\\x8a'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_split(thanks, 'UTF-8').numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b2f9ec",
   "metadata": {},
   "source": [
    "### Byte offsets for characters\n",
    "To align the character tensor generated by `tf.strings.unicode_decode` with the original string, it's useful to know the offset for where each character begins. The method `tf.strings.unicode_decode_with_offsets` is similar to `unicode_decode`, except that it returns a second tensor containing the start offset of each character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "473bce7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At byte offset : 0 | codepoint : 129315 | string scalar : b'\\xf0\\x9f\\xa4\\xa3' | Text : ü§£\n",
      "At byte offset : 4 | codepoint : 127880 | string scalar : b'\\xf0\\x9f\\x8e\\x88' | Text : üéà\n",
      "At byte offset : 8 | codepoint : 127881 | string scalar : b'\\xf0\\x9f\\x8e\\x89' | Text : üéâ\n",
      "At byte offset : 12 | codepoint : 127882 | string scalar : b'\\xf0\\x9f\\x8e\\x8a' | Text : üéä\n",
      "At byte offset : 16 | codepoint : 128519 | string scalar : b'\\xf0\\x9f\\x98\\x87' | Text : üòá\n"
     ]
    }
   ],
   "source": [
    "codepoints, offsets = tf.strings.unicode_decode_with_offsets(u'ü§£üéàüéâüéäüòá', 'UTF-8')\n",
    "\n",
    "for (codepoint, offset) in zip(codepoints.numpy(), offsets.numpy()):\n",
    "    print('At byte offset : {} | codepoint : {} | string scalar : {} | Text : {}'.format(\n",
    "        offset, \n",
    "        codepoint, \n",
    "        tf.strings.unicode_encode([codepoint], output_encoding='UTF-8'),\n",
    "        tf.strings.unicode_encode([codepoint], output_encoding='UTF-8').numpy().decode()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b90e726",
   "metadata": {},
   "source": [
    "## Unicode scripts\n",
    "\n",
    "TensorFlow provides the `tf.strings.unicode_script` operation to determine which script a given codepoint uses. The script codes are `int32` values corresponding to [International Components for Unicode (ICU)](https://icu.unicode.org/home) `UScriptCode` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "edf6f7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17  8]\n"
     ]
    }
   ],
   "source": [
    "uscript = tf.strings.unicode_script([33464, 1041])  # ['Ëä∏', '–ë']\n",
    "\n",
    "print(uscript.numpy())  # [17, 8] == [USCRIPT_HAN, USCRIPT_CYRILLIC]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80307de0",
   "metadata": {},
   "source": [
    "The `tf.strings.unicode_script` operation can also be applied to multidimensional `tf.Tensors` or `tf.RaggedTensors` of codepoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "280d226e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[104, 195, 108, 108, 111],\n",
       " [87, 104, 97, 116, 32, 105, 115, 32, 116, 104, 101, 32, 119, 101, 97, 116,\n",
       "  104, 101, 114, 32, 116, 111, 109, 111, 114, 114, 111, 119]               ,\n",
       " [71, 246, 246, 100, 110, 105, 103, 104, 116], [128522]]>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_chars_ragged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb3ffaef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[25, 25, 25, 25, 25],\n",
       " [25, 25, 25, 25, 0, 25, 25, 0, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25,\n",
       "  0, 25, 25, 25, 25, 25, 25, 25, 25]                                      ,\n",
       " [25, 25, 25, 25, 25, 25, 25, 25, 25], [0]]>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_script(batch_chars_ragged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a0eb2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector :  [25, 25, 25, 25, 25]\n",
      "Text : \u0019\u0019\u0019\u0019\u0019\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Vector :  [25, 25, 25, 25, 0, 25, 25, 0, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 25]\n",
      "Text : \u0019\u0019\u0019\u0019\u0000\u0019\u0019\u0000\u0019\u0019\u0019\u0000\u0019\u0019\u0019\u0019\u0019\u0019\u0019\u0000\u0019\u0019\u0019\u0019\u0019\u0019\u0019\u0019\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Vector :  [25, 25, 25, 25, 25, 25, 25, 25, 25]\n",
      "Text : \u0019\u0019\u0019\u0019\u0019\u0019\u0019\u0019\u0019\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Vector :  [0]\n",
      "Text : \u0000\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "uscript = tf.strings.unicode_script(batch_chars_ragged)\n",
    "# Text vector and string\n",
    "for sentence_chars in uscript.to_list():\n",
    "    print('Vector : ',sentence_chars)\n",
    "    \n",
    "    #Converts vector of code points to an encoded string scalar.\n",
    "    print('Text :',tf.strings.unicode_encode(sentence_chars, output_encoding='UTF-8').numpy().decode())\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a1dcba",
   "metadata": {},
   "source": [
    "## Example: Simple segmentation\n",
    "Segmentation is the task of splitting text into word-like units. This is often easy when space characters are used to separate words, but some languages (like Chinese and Japanese) do not use spaces, and some languages (like German) contain long compounds that must be split in order to analyze their meaning. In web text, different languages and scripts are frequently mixed together, as in \"NYÊ†™‰æ°\" (New York Stock Exchange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5da8865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype: string; shape: [num_sentences]\n",
    "#\n",
    "# The sentences to process.  Edit this line to try out different inputs!\n",
    "sentence_texts = [u'Hello, world.', u'‰∏ñÁïå„Åì„Çì„Å´„Å°„ÅØ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8a84ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[72, 101, 108, 108, 111, 44, 32, 119, 111, 114, 108, 100, 46],\n",
      " [19990, 30028, 12371, 12435, 12395, 12385, 12399]]>\n",
      "<tf.RaggedTensor [[25, 25, 25, 25, 25, 0, 0, 25, 25, 25, 25, 25, 0],\n",
      " [17, 17, 20, 20, 20, 20, 20]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype: int32; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_codepoint[i, j] is the codepoint for the j'th character in\n",
    "# the i'th sentence.\n",
    "sentence_char_codepoint = tf.strings.unicode_decode(sentence_texts, 'UTF-8')\n",
    "print(sentence_char_codepoint)\n",
    "\n",
    "# dtype: int32; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_scripts[i, j] is the Unicode script of the j'th character in\n",
    "# the i'th sentence.\n",
    "sentence_char_script = tf.strings.unicode_script(sentence_char_codepoint)\n",
    "print(sentence_char_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cd3c55",
   "metadata": {},
   "source": [
    "Use the script identifiers to determine where word boundaries should be added. Add a word boundary at the beginning of each sentence, and for each character whose script differs from the previous character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36157c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[True, False, False, False, False, True, False, True, False, False, False,\n",
       "  False, True]                                                             ,\n",
       " [True, False, True, False, False, False, False]]>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtype: bool; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_starts_word[i, j] is True if the j'th character in the i'th\n",
    "# sentence is the start of a word.\n",
    "sentence_char_starts_word = tf.concat(\n",
    "    [tf.fill([sentence_char_script.nrows(), 1], True),\n",
    "     tf.not_equal(sentence_char_script[:, 1:], sentence_char_script[:, :-1])],\n",
    "    axis=1)\n",
    "sentence_char_starts_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09588bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  5  7 12 13 15], shape=(6,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# dtype: int64; shape: [num_words]\n",
    "#\n",
    "# word_starts[i] is the index of the character that starts the i'th word (in\n",
    "# the flattened list of characters from all sentences).\n",
    "word_starts = tf.squeeze(tf.where(sentence_char_starts_word.values), axis=1)\n",
    "print(word_starts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241ce18d",
   "metadata": {},
   "source": [
    "Use those start offsets to build a `RaggedTensor` containing the list of words from all batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec80edc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46],\n",
      " [19990, 30028], [12371, 12435, 12395, 12385, 12399]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype: int32; shape: [num_words, (num_chars_per_word)]\n",
    "#\n",
    "# word_char_codepoint[i, j] is the codepoint for the j'th character in the\n",
    "# i'th word.\n",
    "word_char_codepoint = tf.RaggedTensor.from_row_starts(\n",
    "    values=sentence_char_codepoint.values,\n",
    "    row_starts=word_starts)\n",
    "print(word_char_codepoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44182ff",
   "metadata": {},
   "source": [
    "To finish, segment the word codepoints RaggedTensor back into sentences and encode into UTF-8 strings for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e8af7e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46]],\n",
      " [[19990, 30028], [12371, 12435, 12395, 12385, 12399]]]>\n",
      "\n",
      "Hello, world.\n",
      "‰∏ñÁïå„Åì„Çì„Å´„Å°„ÅØ\n"
     ]
    }
   ],
   "source": [
    "# dtype: int64; shape: [num_sentences]\n",
    "#\n",
    "# sentence_num_words[i] is the number of words in the i'th sentence.\n",
    "sentence_num_words = tf.reduce_sum(\n",
    "    tf.cast(sentence_char_starts_word, tf.int64),\n",
    "    axis=1)\n",
    "\n",
    "# dtype: int32; shape: [num_sentences, (num_words_per_sentence), (num_chars_per_word)]\n",
    "#\n",
    "# sentence_word_char_codepoint[i, j, k] is the codepoint for the k'th character\n",
    "# in the j'th word in the i'th sentence.\n",
    "sentence_word_char_codepoint = tf.RaggedTensor.from_row_lengths(\n",
    "    values=word_char_codepoint,\n",
    "    row_lengths=sentence_num_words)\n",
    "print(sentence_word_char_codepoint)\n",
    "print()\n",
    "\n",
    "for sentence_chars in tf.strings.unicode_encode(sentence_word_char_codepoint, 'UTF-8').to_list():\n",
    "    for char in sentence_chars:\n",
    "        print(char.decode(), end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cfbacf",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2647015a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector :  [2384, 32, 2327, 2306, 32, 2327, 2339, 2346, 2340, 2351, 2375, 32, 2344, 2350, 58]\n",
      "Text : ‡•ê ‡§ó‡§Ç ‡§ó‡§£‡§™‡§§‡§Ø‡•á ‡§®‡§Æ:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Vector :  [2384, 32, 2349, 2370, 2352, 2381, 2349, 2357, 58, 32, 2360, 2381, 2357, 58, 32, 2340, 2340, 2381, 2360, 2357, 2367, 2340, 2369, 2352, 2381, 2357, 2352, 2375, 2339, 2381, 2351, 2306, 32, 2349, 2352, 2381, 2327, 2379, 32, 2342, 2375, 2357, 2360, 2381, 2351, 32, 2343, 2368, 2350, 2361, 2367, 32, 2343, 2367, 2351, 2379, 32, 2351, 2379, 32, 2344, 58, 32, 2346, 2381, 2352, 2330, 2379, 2342, 2351, 2366, 2340, 2381, 2404]\n",
      "Text : ‡•ê ‡§≠‡•Ç‡§∞‡•ç‡§≠‡§µ: ‡§∏‡•ç‡§µ: ‡§§‡§§‡•ç‡§∏‡§µ‡§ø‡§§‡•Å‡§∞‡•ç‡§µ‡§∞‡•á‡§£‡•ç‡§Ø‡§Ç ‡§≠‡§∞‡•ç‡§ó‡•ã ‡§¶‡•á‡§µ‡§∏‡•ç‡§Ø ‡§ß‡•Ä‡§Æ‡§π‡§ø ‡§ß‡§ø‡§Ø‡•ã ‡§Ø‡•ã ‡§®: ‡§™‡•ç‡§∞‡§ö‡•ã‡§¶‡§Ø‡§æ‡§§‡•ç‡•§\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Vector :  [2346, 2357, 2344, 32, 2325, 2369, 2350, 2366, 2352, 32, 2327, 2369, 2306, 2332, 2344]\n",
      "Text : ‡§™‡§µ‡§® ‡§ï‡•Å‡§Æ‡§æ‡§∞ ‡§ó‡•Å‡§Ç‡§ú‡§®\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Canvert Text to UTF8-encoded string.\n",
    "\n",
    "Test_batch_utf8 = [s.encode('UTF-8') for s in [u\"‡•ê ‡§ó‡§Ç ‡§ó‡§£‡§™‡§§‡§Ø‡•á ‡§®‡§Æ:\",\n",
    "                                               u'‡•ê ‡§≠‡•Ç‡§∞‡•ç‡§≠‡§µ: ‡§∏‡•ç‡§µ: ‡§§‡§§‡•ç‡§∏‡§µ‡§ø‡§§‡•Å‡§∞‡•ç‡§µ‡§∞‡•á‡§£‡•ç‡§Ø‡§Ç ‡§≠‡§∞‡•ç‡§ó‡•ã ‡§¶‡•á‡§µ‡§∏‡•ç‡§Ø ‡§ß‡•Ä‡§Æ‡§π‡§ø ‡§ß‡§ø‡§Ø‡•ã ‡§Ø‡•ã ‡§®: ‡§™‡•ç‡§∞‡§ö‡•ã‡§¶‡§Ø‡§æ‡§§‡•ç‡•§',\n",
    "                                               u'‡§™‡§µ‡§® ‡§ï‡•Å‡§Æ‡§æ‡§∞ ‡§ó‡•Å‡§Ç‡§ú‡§®']]\n",
    "\n",
    "# Converts UTF-8 encoded string scalar to a vector of code points.\n",
    "Test_batch_chars_ragged = tf.strings.unicode_decode(Test_batch_utf8,\n",
    "                                                    input_encoding='UTF-8')\n",
    "# Text vector and string\n",
    "for sentence_chars in Test_batch_chars_ragged.to_list():\n",
    "    print('Vector : ',sentence_chars)\n",
    "    \n",
    "    #Converts vector of code points to an encoded string scalar.\n",
    "    print('Text :',tf.strings.unicode_encode(sentence_chars, output_encoding='UTF-8').numpy().decode())\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18e67d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡•ê ‡§ó‡§Ç ‡§ó‡§£‡§™‡§§‡§Ø‡•á ‡§®‡§Æ:\n",
      "‡•ê ‡§≠‡•Ç‡§∞‡•ç‡§≠‡§µ: ‡§∏‡•ç‡§µ: ‡§§‡§§‡•ç‡§∏‡§µ‡§ø‡§§‡•Å‡§∞‡•ç‡§µ‡§∞‡•á‡§£‡•ç‡§Ø‡§Ç ‡§≠‡§∞‡•ç‡§ó‡•ã ‡§¶‡•á‡§µ‡§∏‡•ç‡§Ø ‡§ß‡•Ä‡§Æ‡§π‡§ø ‡§ß‡§ø‡§Ø‡•ã ‡§Ø‡•ã ‡§®: ‡§™‡•ç‡§∞‡§ö‡•ã‡§¶‡§Ø‡§æ‡§§‡•ç‡•§\n",
      "‡§™‡§µ‡§® ‡§ï‡•Å‡§Æ‡§æ‡§∞ ‡§ó‡•Å‡§Ç‡§ú‡§®\n"
     ]
    }
   ],
   "source": [
    "uscript = tf.strings.unicode_script(Test_batch_chars_ragged)\n",
    "\n",
    "sentence_char_starts_word = tf.concat(\n",
    "    [tf.fill([uscript.nrows(), 1], True),\n",
    "     tf.not_equal(uscript[:, 1:], uscript[:, :-1])],\n",
    "    axis=1)\n",
    "\n",
    "# word_starts[i] is the index of the character that starts the i'th word \n",
    "#(in the flattened list of characters from all sentences).\n",
    "word_starts = tf.squeeze(tf.where(sentence_char_starts_word.values), axis=1)\n",
    "#print(word_starts)\n",
    "\n",
    "# word_char_codepoint[i, j] is the codepoint for the j'th character in the i'th word.\n",
    "word_char_codepoint = tf.RaggedTensor.from_row_starts(\n",
    "    values=Test_batch_chars_ragged.values,\n",
    "    row_starts=word_starts)\n",
    "#print(word_char_codepoint)\n",
    "\n",
    "# sentence_num_words[i] is the number of words in the i'th sentence.\n",
    "sentence_num_words = tf.reduce_sum(\n",
    "    tf.cast(sentence_char_starts_word, tf.int64),\n",
    "    axis=1)\n",
    "\n",
    "\n",
    "# sentence_word_char_codepoint[i, j, k] is the codepoint for the k'th character\n",
    "# in the j'th word in the i'th sentence.\n",
    "sentence_word_char_codepoint = tf.RaggedTensor.from_row_lengths(\n",
    "    values=word_char_codepoint,\n",
    "    row_lengths=sentence_num_words)\n",
    "#print(sentence_word_char_codepoint)\n",
    "\n",
    "for sentence_chars in tf.strings.unicode_encode(sentence_word_char_codepoint, 'UTF-8').to_list():\n",
    "    #print('Vector : ',sentence_chars)\n",
    "    for char in sentence_chars:\n",
    "        print(char.decode(), end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca1938f",
   "metadata": {},
   "source": [
    "#### UScriptCode is useful for Hindi and sanskrit word"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
